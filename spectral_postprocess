#!/bin/bash
#------------------------------------------------------------------------------
# Perform post-processing of final model results, to be used for plots and display
# First parse args and declare a nice wrapper function
exptitle=hs # the general experiment name
suffix= # suffix (denotes alteration of prototypical spindown experiment)?
  # so suffix is NOT related to overall experiment name (which changes control atmos)
### PATCH; MAYBE CHANGE
exptitles=(hsJER hsERA pkJER pkERA)
###
tau=false # get tau?
eofs=true # get EOFs?
climate=true # get the climate stuff?
spindown=false # get spindown ensemble?
equilibrium=false # get supposed "equilibrium" climate?
diffs=false # get the ensemble analysis of equilibrium stuff?
flags="-s -O -P 16" # overwrite existing output, and suppress extra messages
#------------------------------------------------------------------------------
# Option 1: Hardcode things (call this script manually)
kas=(0.04 0.02 0.01)
kas=(40) # just one
# kas=(0.25)
testing=false
filetype=4xdaily_inst
if [ "$HOSTNAME" == "gauss" ]; then
  scratch=/birner-scratch/ldavis # need to use special scratch directory
  storage=/home/ldavis
elif [ "$HOSTNAME" == "euclid" ]; then # everything is in same lib/bin
  scratch=/home/ldavis # not mounted, so plenty of space
  storage=/birner-home/ldavis
else echo "ERROR: Unknown host, must configure library and binary locations before running."; exit
fi
# Option 2: Allow function arguments (helps when implementing automated calls)
# args=($@) # store as array
# [[ "${args[0]}" == "-t" ]] && { testing=true; args=(${args[@]:1}); } || testing=false
# [[ "${args[0]:0:1}" == "-" ]] && { echo "ERROR: Unknown flag."; exit 1; }
# kas=${args[@]:3} # the KAs
# filetype=${args[0]} # filename template
# scratch=$(readlink -f ${args[1]}) # source dir
# storage=$(readlink -f ${args[2]}) # destination dir
# if [ -z $filetype ] || [ -z $scratch ] || [ -z $storage ]; then
#   echo "ERROR: Bad input arguments."
#   exit 1
# fi
# if [ ! -d $scratch ] || [ ! -d $storage ]; then
#   echo "ERROR: Scratch directory \"$scratch\" or storage directory \"$storage\" does not exist."
#   exit 1
# fi
#------------------------------------------------------------------------------
# Helper functions, to post-process the post-processing output
# * For now, get from every file a HEMISPHERE-AVERAGE and NH/SH data
# * Changed mind about this; no longer will get hemisphere means because not
#   necessary/can do it on the fly, and don't need to edit pressure levels.
function Edit() {
  # Edit the input netcdf with ncatted
  # These are so stuff can be plotted with Panoply
  file=$1 # the file
  if [ ! -r $file ]; then
    echo "ERROR: Could not find file $file."
    exit 1
  fi
  # ncatted -O -a edges,pfull,d,, $file 2>/dev/null
  # Get hemisphere-means next; same operation for everything
  # Should be last so easy to remove from workflow; won't penalize the post-processing
  # speed very much probably
  if [[ $(cdo -s ngridpoints $file | head -n 1) -ne 32 ]]; then
    # ngridpoints prints number for each variable; use the head to get first one
    # cdo $flags -ensmean -sellonlatbox,-180,180,0,90 $file \
    #   -invertlat -sellonlatbox,-180,180,-90,0 $file ${file%.*}AVE.nc #2> /dev/null
    cdo $flags -sellonlatbox,-180,180,0,90 $file ${file%.*}NH.nc
    cdo $flags -sellonlatbox,-180,180,-90,0 $file ${file%.*}SH.nc
    cdo $flags -ensmean ${file%.*}NH.nc -invertlat ${file%.*}SH.nc ${file%.*}AVE.nc
    rm $file
  else 
    echo "Hemispheric mean of data was already taken."
    mv $file ${file%.*}AVE.nc
    # catches old workflow, where took hemispheric mean on-the-fly at same time
    # as zonal mean; don't want that now because interferes with getting wind EOFs
  fi
}
#------------------------------------------------------------------------------
# Function to get EOFs and PCs of data
function EOF() {
  levidx=$1
  shopt -s nullglob # will return empty if no match
  if [ -z $levidx ]; then
    echo "ERROR: Must supply level index to EOF function."
    exit 1
  fi
  # Initial check
  # Limit to first 1000 days for now; for consistency between experiments
  files=($input/${filetype}.d[0-9][0-9][0-9][0-9]-d[0-9][0-9][0-9][0-9].nc) # collect into array
  files=($input/${filetype}.d1[0-9]00-d[1-2][0-9]00.nc) # collect into array
  if [[ ${#files[@]} -eq 0 ]]; then
    echo "WARNING: No files available for getting wind EOF."
    return 1
  fi
  # Series
  neof=5 # number of EOFs
  series=series$levidx.nc # name of time series
  commands=(${files[@]/#/-selname,u -sellevidx,$levidx })
    # the hashtag-search prepends to each array element; a %-search would append
  echo "Getting time series at level $levidx from files ${files[@]##*/}."
  # for file in ${files[@]}; do
  #   echo ${file##*/}
  #   ysize=$(cdo griddes $file | grep "ysize" | cut -d "=" -f 2 | xargs)
  #   if [ $ysize -eq 32 ]; then
  #     echo "ERROR: Hemispheres were averaged for $ka."
  #     return 1
  #   fi
  # done
  # echo "YAY: Hemispheres were not averaged for $ka."
  # return 1
  # echo ${commands[@]}
  cdo $flags mergetime ${commands[@]} $series
  # Iterate through regions
  export CDO_WEIGHT_MODE=on
  regions=(NH SH)
  for region in ${regions[@]}; do
    echo "Region $region."
    if [ "$region" == NH ]; then
      selection="-sellonlatbox,-180,180,0,90" # north-hemisphere selection
      gridbox="-gridboxsum,1,32"
    elif [ "$region" == SH ]; then
      selection="-sellonlatbox,-180,180,-90,0" # south-hemisphere selection
      gridbox="-gridboxsum,1,32"
    elif [ "$region" == GLOBE ]; then
      selection="" # entire globe
      gridbox="-gridboxsum,1,64" # entire globe
    else
      echo "ERROR: Unknown region $region."
      return 1
    fi
    eigfile=evals$region$levidx.nc # here, time dimension is EOF
    eoffile=evecs$region$levidx.nc # here, time dimension
    pcfile=pcs$region$levidx.nc # here, 
    # Get the EOFs themselves
    echo "Getting EOFs from the time series at level $levidx."
    cdo $flags eof,$neof -setname,EOF -detrend $selection $series \
      $eigfile $eoffile # save eigenvalues and eigenvectors
    # Next the PCs; must do it manually, but very simple calculation; eofcoeff not needed
    # Will area-weight the full time series, multiply it by each EOF, and standardize the
    # final result; will create one file for each EOF, then merge them
    unset pcs # completely wipe bash array and all elements
    for ieof in $(seq 1 $neof); do # see: https://stackoverflow.com/a/169517/4970632
      i=$(expr $ieof - 1) # bash arrays start at 0, CDO selection starts at 1
      pcs[$i]+="-setname,PC$ieof $gridbox -mul " # get dot product of following two results:
      pcs[$i]+="-mul $selection $series -gridweights $eoffile " # weighted data
      pcs[$i]+="-seltimestep,$ieof $eoffile" # and eigenvector
    done
    echo "Getting PCs from the time series at level $levidx."
    cdo $flags merge ${pcs[@]} $pcfile # merge results of the multiplications
    cdo $flags div -sub $pcfile -timmean $pcfile \
      -timstd $pcfile ${pcfile%.*}_std.nc # sub mean, divide by std
    mv ${pcfile%.*}_std.nc $pcfile # overwrite original
    # Finally, get EOFs in physical units by multiplying the standardized
    # values by the original data; result is "anomaly associated with 1 stdev
    # variation of the PC time series"
    echo "Getting EOFs in physical units."
    cdo $flags -timmean -mul -enlarge,$eoffile $pcfile \
      $selection $series eofs$region$levidx.nc # EOFs in physical units;
        # dot product, divided by number of times; remember series is stored without
        # picking hemisphere, so should enlarge to match eoffile
  done # iteration through regions
}
#------------------------------------------------------------------------------
# Equilibrium data, or time-mean of certain number of days at certian point in spindown
# Currently, just final 100 days
function Equilibrium() {
  shopt -s nullglob # will return empty if no match
  # TIME-MEAN OF LAST BLOCK (supposed "EQUILIBRIUM")
  # Only do if last block is at FAR ENOUGH TIME
  outfiles=()
  ### TEMPORARY FIX; CAN CHANGE THIS LOOP IF YOU WANT
  for tspindown in {10..11}00; do
    files=($input/${filetype}.d$tspindown-spindown$suffix-d[0-9][0-9][0-9][0-9]-d[0-9][0-9][0-9][0-9].nc)
    echo "Number of files in $tspindown run: ${#files[@]}."
    [ ${#files[@]} -le 1 ] && continue
      # this is PATCH for old workflow where we only did 100-day spindowns
    cdo $flags timmean ${files[-1]} $fequilibrium-$tspindown.nc #2>>$log # just want last one, alphabetically sorted; will vary length of run
    outfiles+=($fequilibrium-$tspindown.nc)
  done
  # ENSEMBLE-MEAN OF THE EQUILIBRIUM CLIMATES
  echo "Getting ensemble mean equilibrium climate from ${outfiles[@]}..."
  cdo $flags ensmean ${outfiles[@]} $fequilibrium-ensemble.nc
  # Then EDIT EVERYTHING
  # for outfile in ${outfiles[@]}; do
  #   Edit $outfile
  # done
  # Edit $fequilibrium-ensemble.nc
}
# Spindown data, or progress of given spindown with time-resolution preserved
function Spindown() {
  # MERGE all blocks into single time-series
  # for tspindown in {10..99}00; do
  outfiles=() # record files created
  list=({10..60}00)
  list=(1000) # just this one, for now
  for tspindown in ${list[@]}; do
    files=($input/${filetype}.d$tspindown-spindown$suffix-d[0-9][0-9][0-9][0-9]-d[0-9][0-9][0-9][0-9].nc)
    echo "Number of files in $tspindown run: ${#files[@]}."
    [ ${#files[@]} -le 2 ] && continue
      # this is PATCH for old stupid workflow where we only saved first 100 days + last 100 days
    cdo $flags mergetime ${files[@]} $fspindown-$tspindown.nc #2>>$log
    outfiles+=($fspindown-$tspindown.nc)
    # [ -r $fspindown-$spindown.nc ] && rm $fspindown-$tspindown.nc
    # Finally EDIT stuff created into NH/SH/AVE versions
    # for outfile in ${outfiles[@]}; do
    #   Edit $outfile
    # done
  done
  if false; then
    # From results, get ENSEMBLE MEAN of full spindown process
    echo "Getting spindown ensemble from files ${outfiles[@]##*/}..."
    cdo $flags ensmean ${outfiles[@]} $fspindown-ensemble.nc #2>>$log
    # Then EDIT the result
    # Edit $fspindown-ensemble.nc
  fi
}
# Finally get ensemble-statistics for equilibrium climate files
# Get the selected difference for given days, and statistics
function Diffs() {
  region=$1
  tspindown1=$2
  tspindown2=$3
  if [ -z $region ] || [ -z $tspindown1 ] || [ -z $tspindown2 ]; then
    echo "ERROR: Must supply Diffs() function with region and times you wish to compare."
    return 1
  fi
  # Get list of files
  shopt -s nullglob
  file1=$fequilibrium-$tspindown1$region.nc
  file2=$fequilibrium-$tspindown2$region.nc
  files=($fequilibrium-[0-9][0-9][0-9][0-9]$region.nc)
  if [ -z $files ]; then
    echo "WARNING: Could not find any equilibrium climate files."
    return 1
  fi
  echo $file1
  echo $file2
  if [ ! -r $file1 ] || [ ! -r $file2 ]; then
    echo "WARNING: Could not find the selected equilibrium climate files."
    return 1
  fi
  # Our selected difference
  echo "First the selected difference."
  cdo $flags sub $file1 $file2 $fequilibrium-diff$region.nc
  # Bootstrap the differences
  echo "Next bootstrap random differences, and get the standard deviation."
  length=${#files[@]}
  for i in {1..1000}; do
    ch1=$(expr $RANDOM % $length) # random int32, find remainder
    ch2=$(expr $RANDOM % $length)
    while [ $ch1 -eq $ch2 ]; do
      ch2=$(expr $RANDOM % $length) # repeat until two DIFFERENT choices
    done
    cdo $flags sub ${files[$ch1]} ${files[$ch2]} boot$(printf "%04d" $i)$region.nc
  done
  # Just get every single possible difference instead
  # echo "Next get the difference of every single possible pair, and percentiles."
  # maxid=$(expr ${#files[@]} - 1) # maximum ID is length - 1
  # for ch1 in $(seq 0 $maxid); do
  #   for ch2 in $(seq $(expr $ch1 + 1) $maxid); do
  #     cdo $flags sub ${files[$ch1]} ${files[$ch2]} \
  #       boot$(printf "%02d" $ch1)$(printf "%02d" $ch2)$region.nc
  #   done
  # done
  # Standard deviation and percentiles of differences
  files=(boot[0-9][0-9][0-9][0-9]$region.nc) # will delete these later
  cdo $flags ensstd ${files[@]} $fequilibrium-diffstd$region.nc
  if [ -x /usr/bin/cdo ]; then # anaconda version still uses integer params
    /usr/bin/cdo -s -O enspctl,2.5 ${files[@]} $fequilibrium-difflo$region.nc
    /usr/bin/cdo -s -O enspctl,97.5 ${files[@]} $fequilibrium-diffhi$region.nc
      # apparently if try to use -P flag, will NOT EXEUCTE IN PARALLEL
  else echo "WARNING: Could not find CDO version with float-parameter percentile."
  fi
  rm ${files[@]} # remove the helper files
  # cdo $flags ensstd1 ${files[@]} $fequilibrium-std.nc
}
#------------------------------------------------------------------------------
# Control climate data, and reference to other control climates
function Climate() {
  shopt -s nullglob # will return empty if no match
  files=($input/${filetype}.d[0-9][0-9][0-9][0-9]-d[0-9][0-9][0-9][0-9].nc) # collect into array
  if [ -z $files ]; then
    echo "WARNING: Could not find any control-run/climate files."
    return 1
  fi
  echo "Getting climate from files ${files[@]##*/}..."
  ntime=$(cdo -s ntime ${files[0]}) # test time
  [ $ntime -eq 1 ] && timmean="" || timmean="-timmean"
  [ -z "$timmean" ] && echo "Time-mean of control files already taken." \
    || echo "Control files need time-mean."
  commands=("${files[@]/#/${timmean} }") # the hashtag-search prepends; a %-search would append
  cdo $flags ensmean ${commands[@]} $fclimate.nc #2>>$log # the averages at each time
  # Then EDIT the result
  # Edit $fclimate.nc
}

#------------------------------------------------------------------------------
# Run post-processing tasks for all the spindown rates
# This is the main block; function will read global vars declared below
# suffixes=("" 2 3)
# for suffix in "${suffixes[@]}"; do
shopt -s nullglob
### PATCH; MAYBE CHANGE
for exptitle in ${exptitles[@]}; do
###
for ka in ${kas[@]}; do
  kref=40 # can change this manually, but follows logically; is HS value
  # expref=exp$kref # directory for reference maps
  # expname=exp$ka # experiment directory
  expref=$exptitle$(printf "%07.3f" $kref)
  expname=$exptitle$(printf "%07.3f" $ka)
  if $testing; then expname=test; fi
  # Directories
  input=$scratch/$expname/netcdf # location of data
  if [ ! -d $input ]; then
    echo "ERROR: Could not find input directory $input."
    exit 1
  fi
  outputbase=$storage/data # general output location
  [ ! -d $outputbase ] && mkdir $outputbase
  output=$outputbase/$expname # directory for this experiment
  [ ! -d $output ] && mkdir $output
  refloc=$outputbase/$expref # reference directory
  echo $output
  cd $output # move here
  # File management/names
  fclimate=$filetype.climate # output prefix
  fspindown=$filetype.spindown$suffix # output prefix (need spindown info)
  fequilibrium=$filetype.equilibrium$suffix # output prefix (need spindown info)
  # Log prefix
  # log=log/log.
  [ ! -d log ] && mkdir log
  log=log/ # put in subdirectory

  #----------------------------------------------------------------------------
  # Some basic processing
  # First get climate data
  $climate && { # needs to be done before other stuff
    echo "Control climate (KA=$ka)"
    Climate &>${log}climate & # this must finish before others
    }
  wait
  # Spindown processing
  $spindown && {
    echo "Processing the spindown$suffix data (KA=$ka)."
    Spindown &>${log}spindown$suffix &
    }
  wait
  # "Equilibrium" climates
  # TODO needs work, equilibium state not established
  # # # $equilibrium && {
  # # #   echo "Getting the equlibrium$suffix climates (KA=$ka)."
  # # #   Equilibrium &>${log}equilibrium$suffix &
  # # #   }
  # # # wait
  # Statistics on multiple spindown results
  if $diffs; then
    regions=(NH SH)
    for region in ${regions[@]}; do
      echo "Getting difference-equilibrium-stats for $region (KA=$ka)."
      if [ "$region" == "NH" ]; then
        tspindown1=2300 # high PC
        tspindown2=3700 # low PC
      elif [ "$region" == "SH" ]; then
        tspindown1=3300 # low PC
        tspindown2=5700 # high PC
      else
        echo "ERROR: Unknown region $region."
        return 1
      fi
      Diffs $region $tspindown1 $tspindown2 &>${log}diffs$region &
      # wait # wait
    done
  fi
  wait

  #----------------------------------------------------------------------------
  # Next call the spindown-rate-computing function
  file2=${fclimate}AVE.nc
  file1=${fspindown}-ensembleAVE.nc
  file3=${fequilibrium}-ensembleAVE.nc
  if $tau && [ -r $file1 ] && [ -r $file2 ] && [ -r $file3 ]; then
    echo "Esimating tau/timescales (KA=$ka)"
    python3 &>${log}tau << EOF
import spectral # file with all python utilities
spectral.tau("$file1", climate="$file2", equilibrium="$file3", output="$output", ka=$ka, ks=4)
EOF
  elif $tau; then echo "WARNING: One of the files needed for spindown fitting is not available."
  fi

  #----------------------------------------------------------------------------
  # A simple test -- when do we have both hemispheres?
  # files=($input/${filetype}.d1[0-9]00-d[1-2][0-9]00.nc) # collect into array
  # flag=true
  # for file in ${files[@]}; do
  #   # echo ${file##*/}
  #   ysize=$(cdo griddes $file 2>/dev/null | grep "ysize" | cut -d "=" -f 2 | xargs)
  #   if [ $ysize -eq 32 ]; then
  #     echo "ERROR: Hemispheres were averaged for $ka."
  #     flag=false
  #     break
  #   fi
  # done
  # if $flag; then
  #   echo "YAY: Hemispheres were not averaged for $ka."
  # fi
  # continue # in loop

  #----------------------------------------------------------------------------
  # Finally, do some EOF processing
  if $eofs; then
    # Get the eigenvectors, eigenalues, PCs, and EOFs in physical units
    levidxs=({13..36}) # from below 300mb to above 900mb (index 1 is first, not 0)
    echo "Getting EOF stuff (KA=$ka)."
    for levidx in ${levidxs[@]}; do
      EOF $levidx &>${log}eof$levidx & # send to background, every time
      # ### TODO: just for testing
      # EOF $levidx #&>${log}eof$levidx & # send to background, every time
      # break # break out of loop
      # ### Testing done
    done
    wait
    # Combine all the files across levels after parallel processing
    # Default behavior of "merge" will combine same-name variables with identical grids
    # but different pressure levels -- neat!
    echo "Combining output files and removing old ones."
    regions=(NH SH)
    prefixes=(evecs evals pcs eofs)
    for prefix in ${prefixes[@]}; do
      for region in ${regions[@]}; do
        files=($prefix$region[0-9][0-9].nc)
        if [ ${#files[@]} -eq 0 ]; then
          echo "WARNING: Could not find any $prefix files for $region."
          continue
        fi
        cdo $flags merge ${files[@]} $filetype.$prefix$region.nc &>${log}$prefix$region &
      done
    done
    wait # finish parallel
    rm evecs*.nc evals*.nc pcs*.nc eofs*.nc series*.nc # delete series
  fi
done
###
done
###
# done
# tau.model("$taufile", climate="$fclimate", equilibrium="$equilibrium")

#------------------------------------------------------------------------------
# For core management (but most of these CDO commands aren't parallelizeable)
# PostProcess & # run in background
# taskset -cp 20-23 $! # $! == pid of last job run in background
# fg $! # bring back to foreground
# Old stuff
# if [ "$HOSTNAME" == "olbers" ]; then
#   NP=8 # number processors
#   scratch=/home/ldavis # no good place on this server
#   storage=/home/ldavis
# elif [ "$HOSTNAME" == "gauss" ]; then
#   NP=16 # number processors
#   scratch=/birner-scratch/ldavis # need to use special scratch directory
#   storage=/home/ldavis # location where data is backed up
# elif [ "$HOSTNAME" == "euclid" ]; then # everything is in same lib/bin
#   NP=24 # number processors
#   scratch=/home/ldavis # not mounted, so plenty of space
#   storage=/birner-home/ldavis
# else
#   echo "ERROR: Unknown host, must configure library and binary locations before running."
#   exit
# fi
# Spindown with anomalies from climate; but dumb, don't bother
# [ -r $ffull$spindown-absolute.nc ] && rm $ffull$tspindown-absolute.nc
# cdo $flags mergetime $startfile ${files[@]} $ffull$tspindown-absolute.nc #2>>$log
# Edit $ffull$tspindown-absolute.nc
# SAME, but everything w.r.t. climate mean
# Probably NOT NECECESSARY, silly way to duplicate storage
# echo "Getting climate anomaly for spindown from $tspindown."
# regions=(NH SH AVE)
# for region in ${regions[@]}; do
#   if [ ! -r $fclimate$region.nc ]; then
#     echo "WARNING: Could not find climate file $fclimate$region.nc for taking anomalies."
#     continue
#   fi
#   cdo $flags -sub $ffull$tspindown-absolute$region.nc \
#     $fclimate$region.nc $ffull$tspindown-anomalies$region.nc #2>>$log
# done
# # Same, but everything w.r.t. climate mean
# for region in ${regions[@]}; do
#   if [ ! -r $fclimate$region.nc ]; then
#     echo "WARNING: Could not find climate file $fclimate$region.nc for taking anomalies."
#     return 1
#   fi
#   echo "Getting spindown anomalies w.r.t. climate."
#   cdo $flags -sub -delname,C,KE $fspindown-absolute$region.nc \
#     $fclimate$region.nc $fspindown-anomalies$region.nc #2>>$log
# done
# # cdo $flags -sub $fspindown-absolute.nc -enlarge,$fspindown-absolute.nc $fclimate $fspindown-anomalies.nc
