#!/bin/bash
################################################################################
# File for processing results of GFDL model runs AS THEY ARE PRODUCED; use this
# in parallel after every model step while next model step is simultaneously running.
# ---------
# Summary of current variables:
# * with longitude-data:
#   p, t, u, v, z, vor, omega, teq, D, pt, pv s
#   forget dthdp (only will want lapse rate to diagnose mean climate/tropopause
#   heights and can use the mean t/theta fields), but keep S; has physical interpretation
# * without longitude-data:
#   t, u, v, z, vor, omega, teq, D, dthdp, pt, pv, s, **NEW** EHF, EMF, EPF, EKE, C, KE
# Tips:
# Run 'grep -r -l "^[^\!].*register_diag_field(" . | grep ".*\.f90"' at base of source
# directory to see list of files where diag_fields are registered.
################################################################################
# Function for checking NCL scripts success
# Script sometimes fails to spawn child process for displaying time information; ignore these errors
# Also Execute.c is always shown as error alongside specific function error, so ignore that one
function nclcheck() { # input log file as argument
  cat $1 | grep -v "Execute.c" | grep -v "systemfunc" | egrep "^fatal:" &>/dev/null
  return $? # return exit code; good status means we found error, bad status means we found nothing
    # ignore ^warning: because these will also happen if we have a systemfunc error possibly
}
# Global vars
t0=$(date +%s)      # starting time
nckeep=$1           # whether to keep longitudinal data
testing=$2          # check if testing mode enabled; if true, keep all intermediate files
basedir=${0%/*}     # same location as this file; trim filename from right
interpwithcdo=false # interpolate with CDO instead of NCL? much slower during testing (see notes)
hostname=${HOSTNAME%%.*} # trim e.g. monde.atmos.colostate.edu --> monde
mppnccombine=$basedir/mppnccombine # combine; needs to have been compiled here
interpcdo=$basedir/process_interp     # interpolate with CDO
interpncl=$basedir/process_interp.ncl # interpolate with NCL, automatic iteration
# interpncl=$basedir/process_interpex.ncl # interpolate with NCL, explicitly interpolate select variables
params=$basedir/process_params.ncl    # params with NCL
basics=$basedir/process_basic     # zonal means and flux terms with CDO
lorenz=$basedir/process_energy.ncl  # eddy and mean Lorenz energy cycle terms with NCL
# lorenz=$basedir/process_lorenz    # Lorenz energy cycle terms with CDO
# energy=$basedir/process_energy    # Lorenz energy cycle terms with CDO
# Double check some stuff
if [ -z "$nckeep" ]; then
  echo "Error: Must pass bash true/false whether you want to keep original longitude-res data."
  exit 999
fi
if [ -z "$testing" ]; then
  echo "Error: Must pass bash true/false whether you want to use testing mode."
  exit 999
fi
if ! hash ncl 2>/dev/null; then
  echo "Error: NCL is not in $PATH."
  exit 999
fi
if ! hash cdo 2>/dev/null; then
  echo "Error: CDO is not in $PATH."
  exit 999
fi
if ! hash ncrename 2>/dev/null || ! hash ncks 2>/dev/null; then
  echo "Error: NCO is not in $PATH."
  exit 999
fi
if [ ! -x $mppnccombine ]; then
  echo "Error: The mpp combine executable $mppnccombine is missing."
  exit 999
fi
if [ ! -x $basics ]; then
  echo "Error: The script $basics is missing."
  exit 999
fi
if [ ! -x $lorenz ]; then
  echo "Error: The script $lorenz is missing."
  exit 999
fi
if [ ! -r $interpncl ]; then
  echo "Error: The script $interpncl is missing."
  exit 999
fi

################################################################################
# Combine the files produced in parallel
# And check if any netCDF output; see: https://stackoverflow.com/q/2937407/4970632
# if ! compgen -G *.nc > /dev/null; then
# if [ ! -n "$(find . -maxdepth 1 -name "*.nc" -print -quit)" ]; then
# if ! stat -t *.nc > /dev/null 2>&1; then
t=$(date +%s)
for ncfile in *.nc.0000; do
  if [ "$ncfile" == "*.nc.0000" ]; then # make sure nullglob turned off
    echo "Error: No output netcdf files found."
    exit 1 # tell invoking shell that previous model failed
  fi # then combine, if any exist
  files=(${ncfile%%.*}.nc*) # put into array
  echo "Combining files: ${files[@]} into ${ncfile%%.*}.nc"
  $mppnccombine -r ${ncfile%%.*}.nc ${files[@]}
done # -r flag says to remove the decomposed .0000 files after they are combined
  # first arg is output, remaining args are all input
echo "  * Time for combining files: $(($(date +%s) - $t))s."

################################################################################
# THE STDOUT OF THESE LINES IS AN OVERVIEW; SEPARATE STDOUTS FOR CDO/NCL STEPS
# CAN BE FOUND IN SEPARATE LOGS; CHECK THOSE LOGS IF WE HAVE AN ERROR
# Before, this function also accepted averaged data; not anymore, but these are
#   some approaches for testing if file has averaged data
# * [[ " $(cdo -s showname $ncfile) " =~ " time_bounds " ]] # CDO test if averaged
#   isaveraged="print(isfilevar(addfile(\"$ncfile\",\"r\"),\"time_bounds\"))"
# * [ $(ncl -Q -n <<< "$isaveraged") == "False" ] # NCL test if averaged
# * [[ ! " $(ncvarlist $ncfile) " =~ " time_bounds " ]] # NCO test if averaged
[ ! -d ../netcdf ] && mkdir ../netcdf # make directory if doesn't exist
for ncfile in *.nc; do
  # Determine file names
  if $testing; then # special names, and keep in same folder
    outfile="${ncfile%%.*}_summary.nc" # longitude-averaged data
    origfile="${ncfile%%.*}_full.nc" # original data
  else
    outfile="../netcdf/${ncfile%%.*}_summary.${PWD##*/}.nc" # longitude-averaged data
    origfile="../netcdf/${ncfile%%.*}_full.${PWD##*/}.nc" # original data
  fi
  # Apply some simple modifications to attributes
  ncrename -d pfull,mlev $ncfile &>/dev/null # mlev is the ECHAM convention, needed for CDO interpolation
  ncrename -d phalf,ilev $ncfile &>/dev/null # ilev is the other ECHAM convention
  ncrename -v pfull,mlev $ncfile &>/dev/null # -d renames dimensions, -v renames variables of same name
  ncrename -v phalf,ilev $ncfile &>/dev/null
  ncatted -O -a bounds,mlev,o,c,"ilev" $ncfile
  ncatted -O -a long_name,udamp,o,c,"Rayleigh damping of zonal wind" $ncfile
  ncatted -O -a long_name,vdamp,o,c,"Rayleigh damping of meridional wind" $ncfile
  ############################################################################
  interpfile=${ncfile%%.*}_interp.nc
  # 1) Interpolate the data to pressure levels
  # a) Use CDO for interpolation
  t=$(date +%s)
  if $interpwithcdo; then
    echo "Interpolating with CDO..."
    $interpcdo $ncfile $interpfile &>log.interp # that simple babe
    [ $? != 0 ] && echo "Error: Something failed during CDO interpolation." && exit $?
    ! $testing && rm interp?.nc
  # b) Use NCL vint2hp_ecmwf for interpolation
  else
    echo "Interpolating with NCL..." # -Q = no banner, -n = do not enumerate print statements
    ncl -n -Q "filename=\"$ncfile\"" "outfile=\"$interpfile\"" $interpncl &>log.interp #2> /dev/null
    if nclcheck log.interp || [ ! -r $interpfile ]; then
      echo "Error: Something failed during NCL interpolation." && exit 2
    fi
  fi
  # Standardize attributes
  ncatted -a edges,lon,d,, -a edges,lat,d,, \
    -a axis,lon,o,c,"X" -a axis,lat,o,c,"Y" -a axis,plev,o,c,"Z" \
    -a long_name,plev,o,c,"pressure level" -a units,plev,o,c,"mb" -a bounds,plev,o,c,"plev_bnds" \
    -a long_name,lat,o,c,"latitude" -a units,lat,o,c,"degrees_north" \
    -a long_name,lon,o,c,"longitude" -a units,lon,o,c,"degrees_east" $interpfile
  $testing && ncfile=$interpfile || mv $interpfile $ncfile # move old file on top of new file
  echo "  * Time for interpolation: $(($(date +%s) - $t))s."

  # ##############################################################################
  # # Add some parameters to the longitude-latitude file with NCL
  # t=$(date +%s)
  # echo "Getting extra parameters with NCL..." # -Q = no banner, -n = do not enumerate print statements
  # ncl -n -Q "filename=\"$ncfile\"" $params &>log.params #2> /dev/null
  # if nclcheck log.params; then
  #   echo "Error: Something failed getting extra parameters with NCL." && exit 3
  # fi
  # echo "  * Time for getting extra parameters with NCL: $(($(date +%s) - $t))s."

  ##############################################################################
  # 2) Get extra stuff with CDO commands (either simple zonal mean, or add some stuff)
  # Some of these require the extra variables output by NCL; also meridional flux
  # terms rely on NCL having set poleward==positive in each hemisphere
  # t=$(date +%s)
  echo "Getting basic terms..."
  $basics $ncfile &>log.basic &
  pbasics=$!
  # [ $? != 0 ] && echo "Error: Something failed while getting basic terms." && exit 3
  # echo "  * Time for getting basic terms with CDO: $(($(date +%s) - $t))s."
  ##############################################################################
  # 3) Get energy terms in another file
  # Some of these require the extra variables output by NCL; also meridional flux
  # terms rely on NCL having set poleward==positive in each hemisphere
  # t=$(date +%s)
  echo "Getting Lorenz energy cycle terms..."
  ncl -n -Q "filename=\"$ncfile\"" $lorenz &>log.lorenz &
  plorenz=$!
  # if nclcheck log.lorenz; then
  #   echo "Error: Something failed getting extra parameters with NCL." && exit 4
  # fi
  # echo "  * Time for getting Lorenz energy terms with NCL: $(($(date +%s) - $t))s."
  ##############################################################################
  # Manage background processes
  # First the basic term
  wait $pbasics # wait for basic terms
  [ $? != 0 ] && echo "Error: Something failed while getting basic terms." && exit 3
  twait=$(tail -1 log.basic | sed 's/[^0-9]*//g')
  echo "  * Time for getting basic terms with CDO: ${twait}s."
  # Next the Lorenz terms
  wait $plorenz # wait for Lorenz terms
  if nclcheck log.lorenz; then
    echo "Error: Something failed getting extra parameters with NCL." && exit 4
  fi
  twait=$(tail -1 log.lorenz | sed 's/[^0-9]*//g')
  echo "  * Time for getting Lorenz energy terms with NCL: ${twait}s."

  ##############################################################################
  # 4) Tidy up
  t=$(date +%s)
  echo "Merging all the terms into one file..."
  # First add back longitudes to NCL calculated terms
  # Hard/annoying/verbose to fix this in NCL so do it here
  for f in energy??.nc; do # absolutely necessary for CDO to detect plev as vertical axis, and need singleton longitude
    cdo -s -setgrid,basic1.nc $f tmp.nc; mv tmp.nc $f # so ugly... kill me...
  done
  # Next apply merge
  cdo -O -s -merge basic?.nc energy??.nc $outfile # will raise errors because edges were deleted, but still referenced by attributes
  ncks -O $outfile $outfile # clever hack; just *alphabetizes* the variables in file, and very fast
  echo "  * Time for merging all the terms into one file: $(($(date +%s) - $t))s."
  # Then remove the temporary files
  ! $testing && rm basic?.nc energy??.nc
  if $nckeep; then
    # Keep the old file
    # Also get divergence, vorticity, streamfunction, and velocity potential
    t=$(date +%s)
    echo "Keeping longitude-resolution file and calculating extra terms..."
    cdo -O -s -uv2dv -selname,u,v $ncfile dv0.nc 1>/dev/null # gets spectral coefs for vor and div
    cdo -O -s -invertlat -sp2gp -dv2ps dv0.nc dv1.nc 1>/dev/null # default names are fine
    cdo -O -s -chname,sd,div,svo,vor -invertlat -sp2gp dv0.nc dv2.nc # better names
    ncap2 -O -s '*f[$lat] = 2*7.292e-5*sin(lat*3.14159/180); absvor = vor+f' dv2.nc dv2.nc
      # get absolute vorticity; asterisk means this is a "RAM" variable, not saved in final output
    if [ ! -r dv0.nc ] || [ ! -r dv1.nc ] || [ ! -r dv2.nc ]; then
      echo "Warning: Could not get the vorticity/divergence/streamfunction terms."
      ! $testing && rm dv?.nc # remove any that may exist
      mv $ncfile $origfile
    else
      cdo -O -s -merge $ncfile dv1.nc dv2.nc $origfile
      ! $testing && rm dv?.nc
      ! $testing && rm $ncfile
    fi
    echo "  * Time for getting extra div/vor/streamfunc terms from original file: $(($(date +%s) - $t))s."
  else
    # Delete the old file
    echo "Removing longitude-resolution file..."
    ! $testing && rm $ncfile # simple
  fi
done
# Finally, echo time of finish
# Can parse this to send message to the window that ran the runscript/batch runscript
# echo $(($(date +%s) - $t0)) # prints UNIX time difference
echo "TOTAL TIME ELAPSED: $(($(date +%s) - $t0))s."

################################################################################
# Old stuff
# Previous CDO commands
# cdo $flags chname,f0,EHF -zonmean $timmean \
#   -mul -selvar,f0 $ncfile \
#        -div -mul -sub -selvar,pt $ncfile -enlarge,$ncfile -zonmean -selvar,pt $ncfile \
#                  -sub -selvar,v $ncfile -enlarge,$ncfile -zonmean -selvar,v $ncfile \
#             -selvar,dthdp $ncfile \
# cdo $flags chname,u,KE $timmean \
#   -add -divc,9.81 -divc,2 -add -sqr -selvar,u out1.nc \
#                                -sqr -selvar,v out1.nc \
#        -selvar,EKE out5.nc \
#   out7.nc # the total kinetic energy
# Whitespace-safe option for looping through glob results:
# find . -iname "*.nc.0000" | while read ncfile; do
# find . -iname "*.nc" | while read file; do
# Note: 'read' reads each line from standard input and splits line into variable names
# requested (e.g. could have read a b c <<< "foo bar baz"); the while works because exit
# status is 1 during read process, and is 0 when reaching end of file/data stream

