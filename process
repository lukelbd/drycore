#!/bin/bash
################################################################################
# File for processing results of GFDL model runs AS THEY ARE PRODUCED; use this
# in parallel after every model step while next model step is simultaneously running.
# ---------
# Summary of current variables:
# * with longitude-data:
#   p, t, u, v, z, vor, omega, teq, D, pt, pv s
#   forget dthdp (only will want lapse rate to diagnose mean climate/tropopause
#   heights and can use the mean t/theta fields), but keep S; has physical interpretation
# * without longitude-data:
#   t, u, v, z, vor, omega, teq, D, dthdp, pt, pv, s, **NEW** EHF, EMF, EPF, EKE, C, KE
# Tips:
# Run 'grep -r -l "^[^\!].*register_diag_field(" . | grep ".*\.f90"' at base of source
# directory to see list of files where diag_fields are registered.
################################################################################
# Function for checking NCL scripts success
# Script sometimes fails to spawn child process for displaying time information; ignore these errors
# Also Execute.c is always shown as error alongside specific function error, so ignore that one
nclcheck() { # input log file as argument
  cat $1 | grep -v "Execute.c" | grep -v "systemfunc" | egrep "^fatal:" &>/dev/null
}

# Parse input flags
# cores=8 # default cores for mppnccombine, actually this didn't work so nevermind
_dir='.'
_debug=false   # keep data in original folder, instead of moving to ../netcdf? useful for testing
_resume=false  # process old "full" files?
_keepxyz=false # keep original "full" results?
_combine=false # only combine model files, nothing else?
_splitxyz=true # make true the default
nsplit=4 # number of time splits for XYZ files
while [ $# -gt 0 ]; do
  case $1 in
    -c|--combine) echo "Only combining files." && _combine=true ;;
    -q|--quit) echo "Skipping processing." && exit 0 ;;
    -d=*|--dir=*) _dir=${1##*=} ;;
    -d|--debug)  _debug=true   ;;  # if true, keep all intermediate files
    -r|--resume) _resume=true  ;; # process old results sitting in the directory
    -k|--keep)   _keepxyz=true ;; # whether to keep longitudinal data
    -s|--split) _splitxyz=true ;; # whether to split XYZ files before combining
    *) echo "Error: Unknown flag \"$1\"." && exit 127 ;;
  esac
  shift # shift by one
done
$_debug && _keepxyz=true
$_resume && _keepxyz=true # we are *reading* from existing XYZ files so definitely don't delete them!

# Global vars
t0=$(date +%s) # starting time
bin=$(readlink -f ${0%/*})  # same location as this file; trim filename from right
run=mpirun # for running mppnccombine on Cheyenne; parallelization really necessary
interp_cdo=$bin/process_interp.cdo # interpolate with CDO
interp_ncl=$bin/process_interp.ncl # interpolate with NCL, automatic iteration
mppnccombine=$bin/mppnccombine.x # combine; needs to have been compiled here
process=$bin/process_params.ncl  # eddy and mean Lorenz energy cycle terms with NCL
means=$bin/process_zonmean.ncl   # just gets zonal means
cd $_dir # optionally pass dir argument

# Double check some stuff
[ ! -r $process ]       && echo "Error: The script \"$process\" is missing."          && exit 127
[ ! -r $interp_ncl ]    && echo "Error: The script \"$interp_ncl\" is missing."       && exit 127
[ ! -x $mppnccombine ]  && echo "Error: The executable \"$mppnccombine\" is missing." && exit 127
! hash ncl 2>/dev/null  && echo "Error: NCL is not in $PATH."                         && exit 127
! hash ncks 2>/dev/null && echo "Error: NCO is not in $PATH."                         && exit 127
# ! hash cdo 2>/dev/null  && echo "Error: CDO is not in $PATH."                       && exit 127

################################################################################
# Functions
# Stdout of following lines is overview; view separate logfiles for specifics
################################################################################
# Function for interpolating model levels
hybrid_to_press() {
  # Interplolate to pressure levels from model levels
  local t log filename output suffix
  filename="$1"
  suffix="$2"
  output=${filename%%.*}_interp.$suffix
  log=LOGS/log.interp.${suffix%.nc}
  t=$(date +%s)

  # Apply some simple modifications to attributes
  # NOTE: Use -h to prevent appending history
  ncrename -h -d pfull,mlev -d phalf,ilev $filename &>/dev/null # mlev/ilev is the ECHAM convention, needed for CDO interpolation
  ncrename -h -v pfull,mlev -v phalf,ilev $filename &>/dev/null # -d renames dimensions, -v renames variables of same name
  ncatted -h -O -a bounds,mlev,o,c,"ilev" $filename

  # Interpolation
  echo "Interpolating with NCL..." # -Q = no banner, -n = do not enumerate print statements
  [ -r "$output" ] && rm "$output"
  ncl -n -Q "filename=\"$filename\"" "output=\"$output\"" $interp_ncl &>$log #2> /dev/null
  if nclcheck $log || ! [ -r $output ]; then
    echo "Error: Something failed during NCL interpolation." && exit 2
  fi

  # Add back global attribute
  ncatted -h -O -a NumFilesInSet,global,o,l,$numfiles
  ! $_debug && mv $output $filename # move old file on top of new file
  echo "  * Time for interpolation: $(($(date +%s) - t))s."
}

# Means
means() {
  # Get the zonal means
  local t log filename output suffix
  filename="$1"
  suffix="$2"
  output=means.${suffix}
  log=LOGS/log.means.${suffix%.nc}
  t=$(date +%s)
  echo "Getting zonal means..."
  [ -r "$output" ] && rm "$output"
  ncl -n -Q "filename=\"$filename\"" "output=\"$output\"" $means &>$log
  if nclcheck $log; then
    echo "Error: Something failed while getting zonal means." && exit 4
  fi
  echo "  * Time for getting zonal means: $(($(date +%s) - t))s."
}

# Once, this function also accepted averaged data; not anymore, but these are
# some approaches for testing if file has averaged data
params() {
  # Ouput file names
  local t log filename output suffix
  filename="$1"
  suffix="$2"
  output=params.${suffix}
  log=LOGS/log.params.${suffix%.nc}
  t=$(date +%s)
  echo "Getting other params..."
  [ -r "$output" ] && rm "$output"
  ncl -n -Q "filename=\"$filename\"" "output=\"$output\"" "means=\"means.$suffix\"" $process &>$log
  if nclcheck $log; then
    echo "Error: Something failed while getting other params." && exit 4
  fi
  echo "  * Time for getting other params: $(($(date +%s) - t))s."
}

# Check exit codes
pidcheck() {
  for pid in $@; do
    wait $pid
    if [ $? -ne 0 ]; then
      echo "Error: Bad exit code from one or more of the parallel processes."
      exit 4
    fi
  done
}

################################################################################
# Driver, calls above functions
################################################################################
# Get files
if $_debug; then
  _parallel=true
  files=(test.nc.0000) # doesn't really exist
elif $_resume; then
  _parallel=false
  files=(*_full.${PWD##*/}.nc) # the preserved output file
else
  _parallel=true
  files=(*.nc.0000)
fi
if [[ "$files" =~ "*" ]]; then
  files=(*.nc) # already present?
  [ ${#files[@]} -eq 1 ] && echo "Error: XYZ resolution files not found." && exit 1 # make sure nullglob turned off
  echo "Note: Model ran on only 1 core, do not need to merge files."
fi
# Loop through each file
for file in ${files[@]}; do
  ##############################################################################
  # Initial stuff
  ##############################################################################
  # File names and such
  base=${file%%.*}
  if $_debug && $_resume; then
    ncfiles=(${base}.*.nc) # check if already present
  elif $_resume; then
    ncfiles=(${file})
  else
    for part in ${base}.nc*; do
      num=${part##*.}
      mv $part ${base}.${num}.nc & # some programs won't recognize file without .nc extension
    done
    wait # in background
    ncfiles=(${base}.*.nc)
  fi
  echo Files: ${ncfiles[@]}
  numfiles=${#ncfiles[@]}
  xyzfile="${base}_full.${PWD##*/}.nc"   # original data
  yzfile="${base}_summary.${PWD##*/}.nc" # longitude-averaged data
  # Just want to combine files and exit?
  if $_combine; then
    [ -r ${base}.nc ] && rm ${base}.nc
    $mppnccombine -r ${base}.nc ${ncfiles[@]}
    continue
  fi

  ##############################################################################
  # 1) Interpolate to pressure, get means in parallel
  ##############################################################################
  unset pids
  tp=$(date +%s)
  echo "Interpolating and getting means..."
  ! [ -d LOGS ] && mkdir LOGS
  for ncfile in ${ncfiles[@]}; do
    if ! $_debug && $_resume; then
      # Just get means
      num=0000
      suffix=nc # dummy value
      means "$ncfile" "nc" &>LOGS/log.$num &
    else
      # Number
      num=${ncfile%.nc}
      num=${num#*.}
      suffix=${num}.nc
      # Interpolate and get means
      $_debug && mfile=${ncfile%%.*}_interp.$suffix || mfile=$ncfile
      { hybrid_to_press "$ncfile" "$suffix"; means "$mfile" "$suffix"; } &>LOGS/log.$num &
      pids+=($!)
    fi
  done; pidcheck ${pids[@]}
  $_debug && ncfiles=(${base}_interp.*.nc) # we didn't overwrite them
  echo "  * Time for interpolating and getting zonal means in parallel: $(($(date +%s) - tp))s."
  # Merge zonal means
  # NOTE: Use mppnccombine -h to print help info; the -r removes files after
  # run was successful
  if $_parallel; then
    # Merge params
    echo "Combining YZ files..."
    t=$(date +%s)
    [ -r means.nc ] && rm means.nc
    $mppnccombine means.nc means.*.nc
    wait
    echo "  * Time for combining means: $(($(date +%s) - t))s."
  fi

  ##############################################################################
  # 2) Calculate other params in parallel
  ##############################################################################
  # Global means were required for some, hence the initial merge
  unset pids
  tp=$(date +%s)
  echo "Getting other params..."
  for ncfile in ${ncfiles[@]}; do
    # Number
    if $_resume && ! $_debug; then
      num=0000
      suffix=nc # dummy value
    else
      num=${ncfile%.nc}
      num=${num#*.}
      suffix=${num}.nc
    fi
    params "$ncfile" "$suffix" &>>LOGS/log.${num} &
    pids+=($!)
  done; pidcheck ${pids[@]}
  echo "  * Time for getting params in parallel: $(($(date +%s) - tp))s."

  # Merge zonal means
  # NOTE: Use mppnccombine -h to print help info; the -r removes files after
  # run was successful
  if $_parallel; then
    # Merge params
    echo "Combining YZ files..."
    t=$(date +%s)
    [ -r params.nc ] && rm params.nc
    $mppnccombine params.nc params.*.nc &
    wait
    echo "  * Time for combining params: $(($(date +%s) - t))s."
  fi
  # Append params to file; want them to show up at end of ncdump ideally
  # ncks -h --no-abc -A means.nc params.nc
  ncks -h --no-abc -A params.nc means.nc
  if $_debug; then
    cp means.nc $yzfile
  else
    mv means.nc $yzfile
    rm params.nc means.*.nc params.*.nc
  fi

  ##############################################################################
  # 3) Optionally merge the pressure-interpolated files
  # TODO: Consider reducing to a standard horizontal resolution at least, if
  # not vertical? This could save considerable space.
  # NOTE: Had error on Cheyenne where mppnccombine failed for sufficiently
  # big files (threshold was somewhere between 60-80 timesteps at T106 resolution)
  # To fix this, we take time hyperslabs, merge each half, then re-combine
  ##############################################################################
  # Delete the old file
  if ! $_keepxyz; then
    echo "Removing XYZ files..."
    ! $_debug && rm ${ncfiles[@]} # simple
  # Merge files
  # Will drop variables in parallel before merging
  elif ! $_resume; then
    t=$(date +%s)
    unset interp # empty array
    echo "Keeping XYZ files..."
    keep=plev_bnds,latb,lonb,slp,u,v,t
    # Without splitting in half
    if ! $_splitxyz; then
      for ncfile in ${ncfiles[@]}; do
        $_debug && out=${ncfile%%.*}_x.${ncfile#*.} || out=$ncfile
        ncks -O -h --no-abc -v plev_bnds,slp,u,v,t $ncfile $out &
        interp+=($out)
      done; wait
      echo "  * Time for trimming variables: $(($(date +%s) - t))s."
      t=$(date +%s)
      echo "Combine full files."
      [ -r $xyzfile ] && rm $xyzfile
      $mppnccombine -r $xyzfile ${interp[@]}
      [ $? -ne 0 ] && echo "Error: Failed to combine XYZ files." && exit 127
      echo "  * Time for combining XYZ files: $(($(date +%s) - t))s."
    # Split into files of *n* timesteps
    else
      # First a simple test
      ts=$(ncdump -h ${ncfiles[0]} | grep 'UNLIMITED' | sed 's/[^0-9]//g')
      [ -z "$ts" ] && echo "Error: Unknown timesteps for file ${ncfiles[0]}." && exit 127
      [ $((ts % nsplit)) -eq 1 ] && echo "Error: Incompatible number of timesteps ${ts} for ${nsplit} splits." && exit 127
      # Bugfix; had issues with lost memory even on 109GB nodes, maybe has
      # to do with hardware architecture or something
      for ni in $(seq 1 $nsplit); do
        unset outs
        for ncfile in ${ncfiles[@]}; do
          out=${ncfile%%.*}_x${ni}.${ncfile#*.}
          t1=$(((ni - 1)*ts/nsplit)) # e.g. nsplit=10, ts=200, goes 0, 20, 40, 60
          t2=$((ni*ts/nsplit - 1)) # e.g. nsplit=10, ts=200, goes 19, 39, 59
          ncks -O -h --no-abc -d time,$t1,$t2 -v $keep $ncfile $out &
          outs+=" $out"
        done
        interp+=("$outs")
      done; wait
      echo "  * Time for trimming variables: $(($(date +%s) - t))s."
      t=$(date +%s)
      # Combine groups of half-files
      i=1
      unset pids xyzfiles
      echo "Combine pieces..."
      for group in "${interp[@]}"; do
        ixyzfile=${xyzfile%.nc}_${i}.nc
        $mppnccombine -r $ixyzfile $group &
        xyzfiles+=($ixyzfile)
        pids+=($!)
        let i+=1
      done; pidcheck ${pids[@]}
      echo "  * Time for combining XYZ files: $(($(date +%s) - t))s."
      # Put back together
      t=$(date +%s)
      echo "Put back together..."
      ncrcat -O ${xyzfiles[@]} $xyzfile
      ! $_debug && rm ${xyzfiles[@]} ${ncfiles[@]}
      echo "  * Time for putting XYZ files back together: $(($(date +%s) - t))s."
    fi
  fi

  ##############################################################################
  # Then copy files to common directory
  ##############################################################################
  if ! $_debug; then
    ! [ -d ../netcdf ] && mkdir ../netcdf
    [ -r $yzfile ]  && mv $yzfile ../netcdf
    [ -r $xyzfile ] && mv $xyzfile ../netcdf
  fi
done

# Echo time of finish
# Can parse this to send message to the window that ran the runscript/batch runscript
# echo $(($(date +%s) - $t0)) # prints UNIX time difference
echo "TOTAL TIME ELAPSED: $(($(date +%s) - t0))s."
