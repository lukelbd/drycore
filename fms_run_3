#!/bin/bash
# SEE README FILE FOR INSTRUCTION ON NAMELIST/DIAGNOSTIC TABLE
# The runscript, assumes model and mppnccombine are compiled
# Test results for Euclid:
# 8 cores: 100-day Control run, T42 64lats was 1181 seconds
# 12 cores: 100-day Spindown run, T39 60lats was 1022 seconds
# 8 cores: 10-day Control run, T42 64lats was 140 seconds
# 12 cores: 10-day Spindown run, T39 60lats was 111 seconds
ulimit -s unlimited # set max open files
execdir=$PWD/exec.$HOSTNAME # location of executables
exptype=spectral # change this for different file
# exptype=${PWD##*/} # just name of cd, then parameter expansion operation (google this)
#   # two ## trims by longest matching case and one # by shortest matching case
if [ "$HOSTNAME" == "olbers" ]; then
  mpirun=/usr/local/mpich3/bin/mpirun
  scratch=/home/ldavis # no good place on this server
elif [ "$HOSTNAME" == "gauss" ]; then
  mpirun=/usr/local/mpich3-pgi/bin/mpirun
  scratch=/birner-scratch/$USER # need to use special scratch directory
elif [ "$HOSTNAME" == "euclid" ]; then # everything is in same lib/bin
  mpirun=/usr/local/bin/mpirun
  scratch=/home/ldavis # not mounted, so plenty of space
else
  echo "ERROR: Unknown host, must configure library and binary locations before running."
  exit
fi
# if [[ "$PS1" != *"ncl_stable"* ]]; then
# echo $PS1
echo "Entering NCL virtual environment..."
{ . activate ncl_stable; } || { echo "ERROR: ncl_stable environment does not exist. Must install it "\
  "with \"conda create -n ncl_stable -c conda-forge ncl\"."; exit; } # activate NCL environment
fms=$PWD/exec.$HOSTNAME/fms.x # where code is compiled and executable is created
topo=$PWD/topography.data.nc # path to topography input file (optional), must request it in namelist
scripts=$PWD # location of scripts for adding parameters with NCL
mppnccombine=$PWD/exec.$HOSTNAME/mppnccombine # path to executable mppnccombine
# fi

#------------------------------------------------------------------------------
# Functions
#------------------------------------------------------------------------------
# Set up input files for model executable to read; tried to make the function readable
# by matching indentation, which can be done with <<-DELIM; literal tab chars ignored
# https://unix.stackexchange.com/questions/76481/cant-indent-heredoc-to-match-nestings-indent
# Takes two arguments: 1) the working directory, and 2) the iteration mode
function Setup() {
  # Parse input
  current_workdir=$2
  # Set up working directory, and move there
  if [ -d $current_workdir ]; then
    echo "WARNING: working directory ${current_workdir##*/} already exists. Deleting..."
    rm -r $current_workdir
  fi
  echo "Entering work directory $current_workdir..."
  mkdir $current_workdir
  cd $current_workdir
  cp $fms ./fms.x # move executable inside (declared at top of file)
  mkdir RESTART # model spits out stuff here, can be accepted as input to new iteration
  mkdir INPUT   # model reads from this

  # Create namelist with most important properties (for now unchanged)
  kf_input=-${kf}.
  if [ ! "$1" == "spindown" ]; then
    ka_input=-${ka}. # must be negative number for units days
    ks_input=-${ks}. # must be negative number for units days
    days_input=$days_control
  else
    ka_input="0."
    ks_input="0."
    days_input=$days_spindown
  fi
  cat > input.nml << EOF
&main_nml
days     = $days_input,
dt_atmos = $dt_atmos
/
&fms_nml
domains_stack_size = 800000
/
&fms_io_nml
threading_write = 'single',
fileset_write = 'single'
/
&spectral_dynamics_nml
damping_option            = 'resolution_dependent',
damping_order             = 4,
damping_coeff             = 1.15741e-4,
do_mass_correction        = .true.,
do_energy_correction      = .true.,
do_water_correction       = .false.,
use_virtual_temperature   = .false.,
vert_advect_uv            = 'second_centered',
vert_advect_t             = 'second_centered',
longitude_origin          = 0.,
robert_coeff              = .04,
alpha_implicit            = .5,
reference_sea_level_press = 1.e5,
lon_max                   = $(expr $num_lats \* 2),
lat_max                   = $num_lats,
num_levels                = $num_levels,
num_fourier               = $num_fourier,
num_spherical             = $(expr $num_fourier + 1),
fourier_inc               = 1,
triang_trunc              = .true.,
topography_option         = 'flat',
vert_coord_option         = 'even_sigma'
/
&hs_forcing_nml
no_forcing         = .false.,
t_zero             = 315.,
t_strat            = 200.,
delh               = 60.,
delv               = 10.,
eps                = 0.,
sigma_b            = 0.7,
do_conserve_energy = .true.,
trflux             = 1.e-5,
trsink             = -4.,
kf                 = $kf_input,
ka                 = $ka_input,
ks                 = $ks_input
/
EOF

  # Diagnostic table, describes data saved to netCDF
  # First write the header to a file (required always)
  cat > diag_table << EOF
"Model results from the Held-Suarez benchmark"
0 0 0 0 0 0
EOF
  if [ ! "$1" == "spinup" ]; then
    # Output several things; temperature, u component of wind, v component of wind, 
    # temperature tendencies maybe, equilibrium temp, full pressure (because is
    # needed by pot_vort_hybrid NCL function), and sigma levels for reference
    # WARNING: If you accidentally try to output two vars w/ same name, get silent failure
    cat >> diag_table << EOF
# Filenames (name, save-frequency [-1==at end, 0==all, >0==units], save-frequency units, 
# time dimension units, time dimension names)
"6xdaily_inst",  4,   "hours",  1,  "days",  "time",
# Variables to save (module name, fortran name, save name, file name, time-sampling freq 
# for averages, whether we take average, other options, and save size [currently F32]; 
# note cannot save time-average data in same file as non-time-average data, it seems)
"dynamics",    "bk",               "bhalf",  "6xdaily_inst",  "all",  .false.,  "none",  2,
"dynamics",    "pres_full",        "p",      "6xdaily_inst",  "all",  .false.,  "none",  2,
"dynamics",    "temp",             "t",      "6xdaily_inst",  "all",  .false.,  "none",  2,
"dynamics",    "ucomp",            "u",      "6xdaily_inst",  "all",  .false.,  "none",  2,
"dynamics",    "vcomp",            "v",      "6xdaily_inst",  "all",  .false.,  "none",  2,
"dynamics",    "height",           "z",      "6xdaily_inst",  "all",  .false.,  "none",  2
"dynamics",    "vor",              "vo",     "6xdaily_inst",  "all",  .false.,  "none",  2
"dynamics",    "omega",            "omega",  "6xdaily_inst",  "all",  .false.,  "none",  2,
"hs_forcing",  "teq",              "teq",    "6xdaily_inst",  "all",  .false.,  "none",  2,
"hs_forcing",  "diss_heat_rdamp",  "rdamp",  "6xdaily_inst",  "all",  .false.,  "none",  2,
EOF
# "ave",           -1,  "hours",  1,  "days",  "time",
# "8xdaily_ave",   3,   "hours",  1,  "days",  "time",
# "dynamics",    "temp",   "t",    "8xdaily_ave",   "all",  .true.,   "none",  2,
# "hs_forcing",  "teq",    "teq",  "ave",           "all",  .true.,   "none",  2,
# "hs_forcing",  "temp",   "t",    "ave",           "all",  .true.,   "none",  2,
# "dynamics",    "ps",         "p",      "6xdaily_inst",  "all",  .false.,  "none",  2,
# "hs_forcing",  "tdt_ndamp",       "tdt_newtonian",  "6xdaily_inst",  "all",  .false.,  "none",  2,
# "hs_forcing",  "tdt_diss_rdamp",  "tdt_rayleigh",   "6xdaily_inst",  "all",  .false.,  "none",  2,
  fi

  # Miscellaneous stuff
  if [ ! -r $scripts ]; then
    echo "ERROR: could not find NCL-script directory."
    exit
  fi
  touch field_table # just put empty file, if want no tracers
  cp $scripts/*.ncl . # copy over NCL scripts
  [ -r $topo ] && cp $topo INPUT/topography.data.nc # copy topography data, if exists
}

# Function for restarting model; put correct files in correct place so 
# fms.x can read them and continue iteration from a previous state.
# Take one argument: directory where restart files exist
function Restart() {
  # List the restart files for different experiment types
  if [ "$exptype" == "spectral" ]; then
    files_res=("atmos_model.res" "atmosphere.res.nc" "spectral_dynamics.res.nc")
  elif [ "$exptype" == "fv" ]; then
    files_res=("atmos_model.res" "atmos_tracers.res.nc" "fv_rst.res.nc" "fv_srf_wnd.res.nc")
  elif [ "$exptype" == "bgrid" ]; then
    files_res=("atmos_model.res" "atmos_tracers.res.nc" "bgrid_prog_var.res.nc")
  fi

  # Check for existence; if passes, copy over
  restart_dir=$1
  echo "Moving restart files from ${restart_dir##*/}/RESTART to ${PWD##*/}/INPUT..."
  for file in ${files_res[@]}; do
    if [ ! -r $restart_dir/RESTART/$file ]; then
      echo "ERROR: Missing restart file $restart_dir/RESTART/$file"
      exit
    else
      cp $restart_dir/RESTART/$file INPUT/$file
    fi
  done
}

# Run the model and output netcdf files
function Iterate() {
  # Run the model with MPIRUN; also note interestingly there is copy of mpirun
  # in anaconda distribution, could try using that one, see what happens
  # Note that need to use ./fms.x, not fms.x (just as if calling directly)
  echo "Running model..."
  start=$(date +%s)
  $mpirun -np $np ./fms.x 1>/dev/null 2>&1 # send to null
  # $mpirun -np $np ./fms.x 2>&1 | tee -a ../out # tee sends to stdout, and -a appends to file
  echo "Processing time for integration: $(expr $(date +%s) - $start)s."
  rm fms.x # remove executable, because takes up space
  if [ -r INPUT/topography.data.nc ]; then
    rm INPUT/topography.data.nc # remove topography, because takes up space
  fi
  if [ ! "$1" == "spinup" ]; then
    Process $1 # process netCDF output
  fi
}

function Process() {
  [ $timmean ]
  # Process the results and put in convenient location
  # Parallelization produces output for different latitudes, then we combine; will
  # be formatted <name>.0000, <name>.0001, as many files as processors
  # echo "Combining files: $(ls ${ncfile%%.*}.nc.* | xargs) into ${ncfile%%.*}.nc"
  echo "Combining the $np files into single file..."
  for ncfile in *.nc.0000; do
    if [ "$ncfile" == "*.nc.0000" ]; then
      echo "ERROR: NetCDF files are missing. Chances are the model crashed on this iteration."
      exit
    fi # then combine, if any exist
    $mppnccombine -r ${ncfile%%.*}.nc ${ncfile%%.*}.nc.*
  done # -r flag says to remove the decomposed .0000 files after they are combined
    # first arg is output, remaining args are all input
  # Check if any netCDF output; see: https://stackoverflow.com/q/2937407/4970632
  # if ! compgen -G *.nc > /dev/null; then
  # if [ ! -n "$(find . -maxdepth 1 -name "*.nc" -print -quit)" ]; then
  # if ! stat -t *.nc > /dev/null 2>&1; then

  # Iterate over each file specified by diag_table; if this is control data, 
  # will take time-mean; otherwise just take zonal mean. Also only get the
  # extra parameters if we have instant data (NOT time-mean)
  for ncfile in *.nc; do
    [ "$1" == "control" ] && timmean="-timmean" || timmean=""
    isaveraged="print(isfilevar(addfile(\"$ncfile\",\"r\"),\"time_bounds\"))"
    if [ $(ncl -Q -n <<< "$isaveraged") == "False" ]; then\
      # Get more quantities with NCL operations, and add them to
      # the original file; will take their zonal mean later
      echo "Computing NCL parameters..."
      ncl -n -Q "filename=\"$ncfile\"" params.ncl
        # -Q = no banner, -n = no enumerations of print
      # First have issue with "enlarge" command when variables exist with more than one 
      # possible vertical coordinate (bhalf); need to remove them
      cdotime=$(date +%s) # record time for CDO operations
      flags="-s -O -P $np" # need -O because sometimes get prompted to overwrite
      cdo $flags selname,bhalf $ncfile out0.nc
      ncks -O -x -v bhalf $ncfile $ncfile
        # see: http://nco.sourceforge.net/nco.html#Temporary-Output-Files
        # because NCO CREATES TEMPORARY FILES, reading-writing to the same file is an 
        # EXPLICITLY DOCUMENTED FEATURE; but CDO doesn't create temp files, so illegal
      # Get some quantities using CDO operations, add to file
      # allfile=${ncfile%.*}_all.nc # "all" for "all data"
      echo "Computing flux terms for $ncfile..."
      cdo $flags -zonmean $timmean $ncfile out1.nc # original data
      cdo $flags chname,theta,EHF -zonmean $timmean -mul \
            -sub -selvar,theta $ncfile -enlarge,$ncfile -zonmean -selvar,theta $ncfile \
            -sub -selvar,v $ncfile -enlarge,$ncfile -zonmean -selvar,v $ncfile \
            out2.nc # heat flux
      cdo $flags chname,u,EMF -zonmean $timmean -mul \
            -sub -selvar,u $ncfile -enlarge,$ncfile -zonmean -selvar,u $ncfile \
            -sub -selvar,v $ncfile -enlarge,$ncfile -zonmean -selvar,v $ncfile \
            out3.nc # momentum flux
      cdo $flags chname,pv,EPF -zonmean $timmean -mul \
            -sub -selvar,pv $ncfile -enlarge,$ncfile -zonmean -selvar,pv $ncfile \
            -sub -selvar,v $ncfile -enlarge,$ncfile -zonmean -selvar,v $ncfile \
            out4.nc # PV flux
      cdo $flags chname,u,EKE $timmean -divc,9.81 -divc,2 \
        -add -zonmean -sqr -sub -selvar,u $ncfile -enlarge,$ncfile -zonmean -selvar,u $ncfile \
             -zonmean -sqr -sub -selvar,v $ncfile -enlarge,$ncfile -zonmean -selvar,v $ncfile \
            out5.nc # eddy kinetic energy
      cdo $flags chname,t,C -zonmean $timmean -divc,9.81 -mulc,287 \
        -div -zonmean -mul -sub -selvar,t $ncfile -enlarge,$ncfile -zonmean -selvar,t $ncfile \
                           -sub -selvar,omega $ncfile -enlarge,$ncfile -zonmean -selvar,v $ncfile \
             -selvar,p $ncfile out6.nc # vertical heat flux
      cdo $flags chname,u,KE \
        -add -divc,9.81 -divc,2 -add -sqr -selvar,u out1.nc \
                                     -sqr -selvar,v out1.nc \
             -selvar,EKE out5.nc out7.nc # the total kinetic energy
      # Modify attributes
      ncatted -O -a long_name,EHF,m,c,"eddy heat flux" out2.nc
      ncatted -O -a units,EHF,m,c,"K m/s" out2.nc
      ncatted -O -a long_name,EMF,m,c,"eddy momentum flux" out3.nc
      ncatted -O -a units,EMF,m,c,"m2/s2" out3.nc
      ncatted -O -a long_name,EPF,m,c,"eddy PV flux" out4.nc
      ncatted -O -a units,EPF,m,c,"PVU m/s" out4.nc
      ncatted -O -a long_name,EKE,m,c,"eddy kinetic energy" out5.nc
      ncatted -O -a units,EKE,m,c,"J/m2 Pa" out5.nc
      ncatted -O -a long_name,C,m,c,"vertical eddy heat flux" out6.nc
      ncatted -O -a units,C,m,c,"W/m2 Pa" out6.nc
      ncatted -O -a long_name,C,m,c,"total kinetic energy" out7.nc
      ncatted -O -a units,C,m,c,"W/m2 Pa" out7.nc
        # ncatted -O -a edges,pfull,d,, $ncfile
        # delete specification that pfull has edges phalf;
      # Combine zonal mean results
      echo "Taking zonal mean of original parameters..."
      cdo $flags merge out1.nc out2.nc out3.nc out4.nc out5.nc out.nc
    else
      # Just get zonal mean results
      cdotime=$(date +%s) # record time for CDO operations
      echo "Taking zonal mean and time mean of results..."
      cdo $flags zonmean $timmean $ncfile out.nc
    fi
    # Get hemisphere-means, and finally add back in bhalf (couldn't have it before
    # because it was a variable [not dimension] and )
    echo "Taking hemispheric mean and saving to $outfile..."
    [ ! -d ../netcdf ] && mkdir ../netcdf
    outfile="../netcdf/${ncfile%.*}.${PWD##*/}.nc"
    cdo $flags -ensmean -sellonlatbox,-180,180,0,90 out.nc \
      -invertlat -sellonlatbox,-180,180,-90,0 out.nc $outfile
    [ -f out0.nc ] && ncks -A out0.nc $outfile # just appends data from out0.nc to out.nc
    rm out*.nc # remove all "out" files (intermediaries)
    echo "Processing time for CDO commands: $(expr $(date +%s) - $cdotime)s."
    # ncatted -O -a edges,pfull,d,, $ncfile # delete specification that pfull has edges phalf;
    # Possibly delete the longitude-resolution data, or keep (to show video)
    # if [ ]; then
    # fi
  done
  # Whitespace-safe option for looping through glob results:
  # find . -iname "*.nc.0000" | while read ncfile; do
  # find . -iname "*.nc" | while read file; do
  # Note: 'read' reads each line from standard input and splits line into variable names
  # requested (e.g. could have read a b c <<< "foo bar baz"); the while works because exit
  # status is 1 during read process, and is 0 when reaching end of file/data stream
}

#------------------------------------------------------------------------------
# Define the run variables
#------------------------------------------------------------------------------
control=true  # do control run?
spindown=false # do spindown runs?
testing=false # just do test phase?
np=8 # processor count
kf=1 # Rayleigh damping; minus means days
kas=(10 160) # multiple experiments; ks will be this / 10
kas=(40) # for now
dt_atmos=600  # time step, in seconds; default 10min
num_levels=40 # number of vertical levels
# ka=10 # atmosphere; minus means days
# expname=exp10 # for testing
tstart=3000 # first day of integration; set to 0 for new run.
tend=4000   # last day of integration after spin-up
tspindown=(1000 1100 1200 1300 1400 1500 1600 1700 1800 1900 \
  2000 2100 2200 2300 2400 2500 2600 2700 2800 2900) # when to start spindowns
trecord=(1000 1100 1200 1300 1400 1500 1600 1700 1800 1900) # when to record control info
tequilibrium=1000 # which spindown do we run to equilibrium?
tequilbriumend=2000 # when to end run to equilibrium?
tvideo=1000 # when to keep longitude info?
days_control=100 # time-interval for stopping, saving, and restarting control run 
days_spindown=100 # length of time to integrate each spindown run
if $testing; then # overwrite some settings
  tspindown=(1)
  trecord=(1)
  days_control=1
  days_spindown=1
  tend=2
fi
# Derived namelist parameters
case $np in
  [1248]) # Standard case
    num_fourier=42 # truncation level
    num_lats=64 ;; # must be >=(3M+1)/2
  12) # Then use num_fourier=39, num_lats=60 for 12 cores; need number of lats divisible
    # by number of cores and need to allow data to be de-aliased
    num_fourier=39
    num_lats=60 ;;
    # num_fourier=42
    # num_lats=72 ;;
  *)
    echo "ERROR: invalid number of cores."; 
    exit ;;
esac
echo "$np processors: Truncation number $num_fourier with $num_lats latitudes."

#------------------------------------------------------------------------------
# Run the model in blocks of $delta days for control, then choose starting
# points from control for spin-down ensemble experiments
#------------------------------------------------------------------------------
# Run multiple experiments consecutively
for ka in ${kas[@]}; do
  ks=$(expr ka / 10) # keep same ratio of surface/lid cooling rates
  ks=4 # in stratosphere, go to 4 days
  echo "Current cooling rate: $ka days."
  if $control; then
    echo "Running control experiment from day $tstart to day $tend."
  fi
  if $spindown; then
    echo "Running spindown experiments from days ${tspindown[@]}."
  fi
  # Check that executables are present
  expname="exp$ka" # experiment name
  basedir=$scratch/$expname # all results go here
  [ ! -d $basedir ] && mkdir $basedir # make directory
  if [ ! -x $fms ]; then # x for 'executable'
    echo "ERROR: The executable $fms is missing."
    exit
  fi
  if [ ! -x $mppnccombine ]; then
    echo "ERROR: The mpp combine executable $mppnccombine is missing."
    exit
  fi
  # First, control run; then will pick days from that run to start up the spin-down tests
  if $control; then
    # Prepare for the loop
    delta=$days_control # iteration stepping
    pday=$(expr $tstart - $delta)
    cday=$(expr $tstart)
    nday=$(expr $tstart + $delta)
    # Start
    origin=$(date +%s)
    while [ $nday -le $tend ]; do
      # MESSAGE AND RESET TIMER
      echo "Running from day $cday to day $nday."
      time=$(date +%s)
      # RUN THE MODEL and COMBINE OUTPUT
      # current_workdir=$basedir/d$(printf "%04d" $cday)
      previous_workdir=$basedir/d$(printf "%04d" $pday)-d$(printf "%04d" $cday)
      current_workdir=$basedir/d$(printf "%04d" $cday)-d$(printf "%04d" $nday)
      # [ $cday -lt $tspinup ] && mode="spinup" || mode="control"
      [[ " ${trecord[@]} " == *" ${cday} "* ]] && { mode="control"; echo "Recording output."; }\
        || { mode="spinup"; echo "Not recording output."; }
        # tests if in the expansion of array to space-separated values containes " $cday "
      Setup "$mode" "$current_workdir" # sets up working directory, cd into it
      [ $cday -gt 0 ] && Restart "$previous_workdir" # add restart files
      Iterate "$mode"  # run model
      # STEP THINGS FORWARD, FOR NEXT ITERATION
      pday=$cday
      cday=$(expr $pday + $delta)
      nday=$(expr $cday + $delta)
    done
    echo "The control run completed successfully in $(expr $(date +%s) - $origin) seconds!"
  fi

  # Next, the spin-down runs
  # Turn of Newtonian cooling for $delta days from various starting points
  if $spindown; then
    origin=$(date +%s)
    for sday in "${tspindown[@]}"; do
      # MESSAGE AND RESET TIMER
      echo "Running spindown from day $sday of control for $delta days."
      time=$(date +%s)
      # RUN THE MODEL and COMBINE OUTPUT
      restart_dir=$basedir/d$(printf "%04d" $(expr $sday - $days_control))-d$(printf "%04d" $sday)
      current_workdir=$basedir/d$(printf "%04d" $sday)-spindown
      Setup "spindown" "$current_workdir"
      Restart "$restart_dir"
      Iterate "spindown"
      echo "Spindown from day $sday completed in $(expr $(date +%s) - $time) seconds!"
      # POTENTIALLY CONTINUE RUN ALL THE WAY TO EQUILIBRIUM; save TIMEMEAN files along way
      if [ "$sday" == "$equilibrium_day" ]; then
      fi
    done
    echo "The spindown runs completed successfuly in $(expr $(date +%s) - $origin) seconds!"
  fi
done
# . deactivate ncl_stable # de-activate the NCL environment
