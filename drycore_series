#!/bin/bash
################################################################################
# NOTE: Previously sweeped parameter space with ugly hodgpodge of exact doubling;
# dividing into 1, 2.5, 5; and diving into 1, 2, 4; now, we always use the 1, 2, 4
# to logarithmically sweep space. Existing directories have been moved to their
# closest values in this new spacing. White lie, but probably insignificant differences.
################################################################################
doc="Use this to run a parameter sweep for the given input sereis and list(s) of parameters.

Usage:
     drycore_batch \"force_sweep_resolution\" [flags] --1=[rvalue1:]value1,[rvalue2:]value2,... --2=...

Force specification:
  hs,pk,dbt - Held-Suarez 1994, Polvani-Kushner 2004, or Davis, Birner, and Thompson (TBD) parameterization

Sweep specifications:
     base               just run forcing scheme with default settings, once
     katmos[123]        change tropospheric damping; number is boundary layer option
     kstrat[01]         change stratospheric damping; number if troposphere-stratosphere damping transition option
     kfric              change friction
     tgrad              change equator-pole eqtemp difference
     tshift             shift eqtemp meridional gradient poleward or equatorward
     katmos[123]-tgrad  change both tropospheric damping and equator-pole eqtemp difference
     katmos[123]-tshift change both tropospheric damping and temp gradient shift
     katmos[123]-kfric  change both friction and tropospheric damping
                        stratosphere option XX is the depth of

Resolution specification: t[XX]l[YY][spe]
    * First number is truncation number.
    * Second number is level count.
    * Suffix controls level spacing option: [s]imple/even [s]igma, [p]olvani
      kushner spacing, or [e]ra-interim spacing.

Parameter specification flags: Use --1, --2:
    * Which parameter(s) are being changed depends on the experiment series. Most
      just change 1 as diagonal parameter spaces are a huge PITA.
    * To start the run from the end of a *previous* run in the same experiment
      series, use restart_parameter:current_parameter; e.g. call this script
      with --1=10,20,40,40:100,100:200,200:400
    * The final directory name for experiments will be
          force_sweep_resolution_p[XXX]p[YYY]...
      for each parameter. If the parameter has the *base* value (i.e.,
      corresponding roughly to Held-Suarez standard) the sweep will be renamed
      to 'base', and the directory will be named force_*base*_resolution.

Other flags:
    --test  Run quick test, just a few days, maybe 3 restarts.
    --init  Run model for 1 second, save netcdf file with forcing scheme data.
    --mode  The experiment mode, where:
        * 0 is control run
        * 1 for radiation off spindown
        * 2 for radiation off but surface on spindown
        * 3 for everything off (radiation, surface, and friction) spindown
        * 4 for friction off spindown

To customize other things, make direct edits to this script.
"
# Load modules
module load impi &>/dev/null # to parallelize the combine process, need mpirun!
module load nco &>/dev/null
# module load ncl &>/dev/null # use conda versions instead, already on path
# module load cdo/1.9.4 &>/dev/null

# Default settings
# NOTE: Really can't push CFL number! Shoot for around 0.5. Got almost instant
# model blow up at 1200s with T106, since upper-level winds probably get to
# around 100m/s (about 200mph)
# NOTE: Working times so far:
# 20 days, 40 days: 600s, even 800s too fast
# 100 days: 800s
secs=0 # normally is zero
days=50
nodes=1
cores=8
runmode=0
dryrun=false
# dt=600 # for T106, gives 100m/s CFL number of 0.5
dt=600
tstart=0  # first day of integration; set to 0 for new run.
tend=5500 # for new experiments just do 1200 day integrations, first 200 are spinup
walltime=12:00
queue=economy
# queue=regular
# Output settings
outfreq=12      # every 6
frequnits=hours # hours
filename=2xdaily_inst # name for output files
ktstart=3500 # first day we keep XYZ data (can't keep all, too much data)
ktend=5500 # last day we keep XYZ data
# Test settings
testmode=0
testname=test # default name of directory
initname=init
testdays=5
testblocks=1 # number of blocks of testdays
# For supercomputer, idea will be to submit all jobs for the series
# simultaneously, by auto-generating a PBS script
super=false
diag_table=diag_table_default
[[ $HOSTNAME =~ cheyenne* ]] && super=true
# Parse input
unset series_name flags_global
while [ $# -gt 0 ]; do # echo "Flag: $1"
  case "$1" in
    -h|--help) echo "$doc" && exit 0 ;;
    -t|--test) testmode=1 ;;
    -d|--dryrun) dryrun=true ;; # just print function calls?
    -dt=*|--timestep=*) dt=${1#*=} ;;
    -d=*|--days=*)      days=${1#*=} ;;
    -ts=*|--tstart=*)   tstart=${1#*=} ;; # model start time?
    -te=*|--tend=*)     tend=${1#*=} ;;
    -kts=*|--ktstart=*) ktstart=${1#*=} ;; # start time for keeping XYZ files?
    -kte=*|--ktend=*)   ktend=${1#*=} ;; # end time?
    -td=*|--testdays=*)   testdays=${1#*=} ;;
    -tb=*|--testblocks=*) testblocks=${1#*=} ;;
    -tn=*|--testname=*)   testname=${1#*=} ;;
    -in=*|--initname=*)   initname=${1#*=} ;;
    -c=*|-np=*|--cores=*) cores=${1#*=} ;;
    -p=*|--process=*)     pflags="${1#*=}" ;; # extra flags for processing script
    -n=*|--nodes=*) nodes=${1#*=} ;;
    -m=|--mode=*) runmode=${1#*=} ;;
    -1=|--1=*) params1=($(echo ${1#*=} | tr ',' ' ')) ;;
    -2=|--2=*) params2=($(echo ${1#*=} | tr ',' ' ')) ;;
    -*) flags_global+="$1 " ;;
    *) [ -n "$series_name" ] && echo "Error: More than one experiment series specified." && exit 1
       series_name="$1" ;;
  esac; shift # shift by at least one
done
# Default experiment series
if [ -z "$series_name" ]; then
  echo "Warning: No experiment name specified. Running default experiment hs_base_t42l40s."
  sleep 5 # give user time to cancel
  series_name='hs_base_t42l40s'
fi
# Parse experiment series name
# Also echo the critical parallelization info
echo "Nodes: $nodes, Cores: $cores"
force="${series_name%%_*}"
sweep="${series_name#*_}"
sweep="${sweep%%_*}"
reso="${series_name#*_}"
reso="${reso#*_}"
reso="${reso%%_*}"

# Run really fast test run
case $testmode in
1)
  unset flags_global # no resume or new days
  rdir="${force}_base_t95l60e" # override previous directory
  rdays=d0450-d0500 # set restart directory days (leave empty to just use the last subfolder in directory)
  pflags+=" -d" # don't move/delete anything; also implies flags="--keep-xyz "
  outfreq=12
  frequnits=hours
  filename=test
  dt=600
  days=$testdays
  tstart=0
  tend=$((testdays * testblocks))
  ktstart=$tstart
  ktend=$tend
  walltime=01:00 # real quick test
  queue=regular
# Initial conditions, for sanity checks
;; 2)
  unset flags_global # no resume or new days
  cores=1 # easier for debugging, otherwise print statements executed simultaneously
  pflags+=" -q" # do nothing
  outfreq=1
  frequnits=seconds
  filename=init
  dt=1
  days=0
  secs=1
  tstart=0
  tend=0
  queue=priority
;; esac
# Days for keeping
txyzdata=$(seq $ktstart $days $ktend | tr $'\n' ',') # for saving

#------------------------------------------------------------------------------#
# Paths
#------------------------------------------------------------------------------#
# Storage information for runscript and post-processing script
storage=$HOME
scratch=$HOME # on Euclid, home is unmounted/not backed up; so disk I/O is quick
f90dir=$HOME/gfdl-drycore # model code folder
bindir=./drycore-${HOSTNAME%%.*} # compiled model code folder (should be in this folder)
case ${HOSTNAME%%.*} in
  # olbers)
  #   scratch=''
  # ;; gauss)
  #   scratch=/birner-scratch/ldavis # need to use special scratch directory
  euclid)
    storage=/birner-home/ldavis # this directory is backed up; synced with GAUSS home folder
  ;; monde)
    case $reso in
      t42l10s) scratch=/mdata2/ldavis ;;
      t42l20s) scratch=/mdata1/ldavis ;;
      *) echo "Error: Unknown scratch destination for experiment with resolution ${reso}." ;;
    esac
  ;; cheyenne*)
    storage=/glade/u/home/davislu
    scratch=/glade/scratch/davislu # https://www2.cisl.ucar.edu/resources/storage-and-file-systems/glade-file-spaces
    bindir=drycore-cheyenne
  ;; *) echo "Error: Unknown host, must edit batch script before continuing." && exit 1 ;;
esac
! [ -d "$storage/data" ] && { mkdir "$storage/data"; echo "Created storage directory."; }
# Copy over the appropriate executable file
cp $bindir/fms.x ./ # location of executables
[ $? -ne 0 ] && echo "Error: fms.x not found in \"$bindir\"." && exit 1
cp $bindir/mppnccombine.x ./ # location of executables
[ $? -ne 0 ] && echo "Error: mppnccombine.x not found in \"$bindir\"." && exit 1

#------------------------------------------------------------------------------#
# Helper functions
#------------------------------------------------------------------------------#
# Array membership
array_in() {
  [[ " ${@:2} " =~ " ${1} " ]]
}

# Add to arrays storing namelist parameters. Fugly but works.
# * If the <value> part is empty (e.g., if this particular experiment
#   series does not change that value), will not add to arrays
# * Function accounts for situation when you pass an empty string parameter
#   or negative number, and have weird strings like "v-" and "v''"
array_add() {
  while [ $# -ne 0 ]; do
    if [ -n "$2" ] && [ "${#2}" -gt 1 ] && [ "$2" != "v-" ] && [ "$2" != "v''" ]; then
      [ "${2:0:1}" != v ] && echo "Error: Values must be input as v<value>." 1>&2 && exit 1
      nml_params+=("$1")
      nml_values+=("${2#v}")
    fi
    shift 2
  done
}

# Get the model run name
exp_name() {
  # First allow "continuation experiments" -- picking up for new timescale
  # experiment from the end of the control run from an old experiment
  local opt param1 param2 rparam1 rparam2 exp_in exp_out sweep_in sweep_out
  exp_in=$1
  param1=$2
  param2=$3
  sweep_in=${exp_in#*_}
  sweep_in=${sweep_in%%_*}
  if [[ $param1 =~ : ]]; then
    rparam1=${param1%:*}
    param1=${param1#*:}
  fi
  if [[ $param2 =~ : ]]; then
    rparam2=${param2%:*}
    param2=${param2#*:}
  fi
  # Detect whether this is a 'base' experiment. Experiment series can
  # 'intersect' each other, and this ensures we aren't duplicating model runs
  if [ -n "$rparam1" ] && [ -n "$rparam2" ]; then
    echo "Error: Cannot do 'diagonal' continuation experiments." 1>&2
    exit 1
  fi
  # This loop will be through only 1 or 2 params, since we enforce at least
  # rparam1 or rparam2 are empty. Idea is restarts should be taken from the
  # end of an experiment where only *one* param was changed.
  for p1 in $rparam1 $param1; do
    for p2 in $rparam2 $param2; do
      # Continuation experiments
      # NOTE: Continue from the *preceding* continuation experiment if possible,
      # rather than from a cold start
      unset c
      if [ -n "$exp_out" ]; then
        c=c
        rdir=$exp_out
        if ! [[ $rdir =~ base ]]; then
          rdir=${rdir}c
        fi
      fi
      # Get experiment sweep name, *ensuring that we avoid duplicating runs
      # by deferring to different names when possible*
      opt=${sweep_in%-*}
      opt=${opt##*[a-z]} # get the option
      sweep_out=$sweep_in # by default, will be same
      case $sweep_in in
        # 1D paramter sweeps
        katmos[123])
          [[ $p1 == 40 ]] && sweep_out=base p1=
          ;; # base is 40 day zonal-mean or anomaly damping
        katmos[123]-fixed)
          [[ $p1 == 40 ]] && sweep_out=base-fixed p1=
          ;; # no 'base' because background damping always huge
        tgrad)
          [[ $p1 == 60 ]] && sweep_out=base p1=
          ;; # base is 60K contrast
        tshift)
          [[ $p1 == 0 ]] && sweep_out=base p1=
          ;; # zero just means no shift
        kfric)
          [[ $p1 == 1  ]] && sweep_out=base p1=
          ;;
        kstrat[01])
          [[ $p1 == 40 ]] && sweep_out=base p1=
          ;;
        # 2D paameter spaces
        katmos[123]-tgrad)
          [[ $p1 == 40 && $p2 == 60 ]] && sweep_out=base p1= p2=
          [[ $p1 == 40 ]] && sweep_out=tgrad p1=$p2 p2=
          [[ $p2 == 60 ]] && sweep_out=katmos$opt p2=
          ;;
        katmos[123]-tshift)
          [[ $p1 == 40 && $p2 == 0 ]] && sweep_out=base p1= p2=
          [[ $p1 == 40 ]] && sweep_out=tshift p1=$p2 p2=
          [[ $p2 == 0 ]] && sweep_out=katmos$opt p2=
          ;;
        tgrad-tshift)
          [[ $p1 == 60 && $p2 == 0 ]] && sweep_out=base p1= p2=
          [[ $p1 == 60 ]] && sweep_out=tshift p1=$p2 p2=
          [[ $p2 == 0 ]] && sweep_out=tgrad p2=
          ;;
        katmos[123]-kfric)
          [[ $p1 == 40 && $p2 == 1 ]] && sweep_out=base p1= p2=
          [[ $p1 == 40 ]] && sweep_out=kfric p1=$p2 p2=
          [[ $p2 == 1 ]] && sweep_out=katmos$opt p2=
          ;;
        *)
          echo "Error: Unknwon experiment \"${sweep_in}\"."
          exit 1
          ;;
      esac
      [ "$p1" == na ] && unset p1
      [ "$p2" == na ] && unset p2
      [ -n "$p1" ] && p1="_p$(printf "%08.3f" $p1)"
      [ -n "$p2" ] && p2="p$(printf "%08.3f" $p2)"
      exp_out=${force}_${sweep_out}_${reso}${p1}${p2}${c}
    done
  done
  echo $exp_out
}

# Determine namelist changes and diag table changes
# WARNING TODO: Currently don't explicitly declare all param variables; they
# are global values, and if not reset on every iteration of diagonal experiment,
# could get unexpected namelist values! Make sure to unset variables that are
# changed in a param sweep.
exp_setup() {
  # Parse the experiment name, figure out what needs to be written
  # The 'p values' are values specified in experiment name as pXXXpYYYpZZZ
  unset kbl ktrop kstrat kmeso kdepth stratdamp delh exph
  local nml_params nml_values p_values message
  local exp_name=$1
  exp_sweep=${exp_name#*_}
  exp_sweep=${exp_sweep%%_*}
  if ! [ $exp_sweep == base ]; then
    p_values=${exp_name##*_}
    p_values=${p_values%c}
    p_values=($(echo $p_values | tr -t p ' ' | xargs printf "%.3f "))
  fi
  # echo $exp_name 1>&2
  # echo ${p_values[@]} 1>&2
  #----------------------------------------------------------------------------#
  # Add to this as you design new experiment series
  #----------------------------------------------------------------------------#
  fixed="-0.1" # timescale used to 'fix' temperature field; difficult to prevent model blowup!
  case $exp_sweep in
    # Base
    base*)
      if [[ $exp_sweep =~ -fixed$ ]]; then
        ktrop="$fixed,-40"
        kbl="$fixed,-4"
      fi

    # The equator-pole equilibrium difference
    ;; tgrad) # temp gradient experiments
      delh=${p_values[0]}

    # Perturb the equator-pole temp gradient
    ;; tshift)
      exph=${p_values[0]}

    # Friction
    ;; kfric) # friction experiments
      kfric=-${p_values[0]}

    # Damp full atmosphere
    # Also includes diagonal experiments where multiple params changed
    ;; katmos[123]*)
      # First set mean and anomaly components of troposphere damping
      prefix=${exp_sweep%-*}
      suffix=${exp_sweep#*-}
      ktrop=-${p_values[0]}
      if [[ $exp_sweep =~ katmos[123]-kfric ]]; then
        kfric=-${p_values[1]} # diagaonal experiment
        [ -z "$kfric" ] && echo "Error: Need second param for diagonal experiment." && exit 1
      elif [[ $exp_sweep =~ katmos[123]-tgrad ]]; then
        delh=${p_values[1]} # diagaonal experiment
        [ -z "$delh" ] && echo "Error: Need second param for diagonal experiment." && exit 1
      elif [[ $exp_sweep =~ katmos[123]-tshift ]]; then
        exph=${p_values[1]} # diagaonal experiment
        [ -z "$exph" ] && echo "Error: Need second param for diagonal experiment." && exit 1
      elif [ "$suffix" == anom ]; then
        ktrop="-40,$ktrop"
      elif [ "$suffix" == mean ]; then
        ktrop="$ktrop,-40"
      elif [ "$suffix" != fixed ] && [ "$suffix" != "$exp_sweep" ]; then
        echo "Error: Unknown suffix option ${suffix}." 1>&2
        exit 1
      fi
      kstrat=$ktrop # if hs forcing, will not change anything
      kmeso=$ktrop
      # Next, separately scale boundary layer damping rate
      unset kbl
      blopt=${prefix##*[a-z]} # get number
      for iktrop in ${ktrop/,/ }; do
        case "$blopt" in
          [01]) ikbl=-4 ;; # hold boundary layer value constant
          2) ikbl=-$(bc -l <<< "scale=3; ${iktrop#-}/10") ;; # hold ratio constant; i.e. keep it at 10
          3) ikbl=-$(bc -l <<< "scale=3; (4^-1 + (${iktrop#-}^-1 - 40^-1))^-1") ;; # preserve 'boundary layer' component
          *)
            echo "Error: Unknown blopt ${blopt}." 1>&2
            exit 1 ;;
        esac
        kbl=$kbl,$ikbl # mean and anomaly components
      done
      kbl=${kbl#,} # trim leading comma
      # Special fixes background state case
      if [ "$suffix" == fixed ]; then
        ktrop="$fixed,$ktrop" # model breaks on scale of minutes, but seems to handle 1 hour o.k. (i.e. 0.05days)
        kbl="$fixed,$kbl"
      fi

    # Damp stratosphere
    ;; kstrat[01]) # stratosphere damping experiments
      # Parse the depth and stuff
      prefix=${exp_sweep%-*}
      suffix=${exp_sweep#*-}
      kstrat=-${p_values[0]}
      kdepth=${p_values[1]} # param 2 is depth of transition region
      if [ -z "$kdepth" ]; then
        echo "Error: Need to specify transition depth as second parameter." 1>&2
        exit 1
      fi
      stratdamp=${prefix##*[0-9]}
      if [ "$stratdamp" == 0 ]; then
        stratdamp=constant
      elif [ "$stratdamp" == 1 ]; then
        stratdamp=linear
      else
        echo "Error: Unknown stratosphere damping option ${stratdamp}." 1>&2
        exit 1
      fi
      # Detect other options
      if [ "$suffix" == anom ]; then
        kstrat="-40,$kstrat"
      elif [ "$suffix" == fixed ]; then
        kstrat="$fixed,$kstrat" # model breaks on scale of minutes, but seems to handle 1 hour o.k. (i.e. 0.05days)
      elif [ "$suffix" == mean ]; then
        kstrat="$kstrat,-40"
      elif [ -n "$suffix" ]; then
        echo "Error: Unknown suffix option ${suffix}." 1>&2
        exit 1
      fi

    # Unknown
    ;; *) echo "Error: Unknown experiment series \"$exp_sweep\"." 1>&2
          exit 1
  ;; esac

  #----------------------------------------------------------------------------#
  # Store namelist changes in two arrays, so we can also
  # nicely print those changes
  #----------------------------------------------------------------------------#
  # Forcing settings
  array_add delh v$delh exp_h v$exph
  array_add strat_mode v\'$force\' strat_damp v\'$stratdamp\'
  array_add ktrop v$ktrop kfric v$kfric kbl v$kbl kstrat v$kstrat kmeso v$kmeso z_kdepth v$kdepth
  # Timing variables
  # These ones are not experiment dependent so far, and are *global*
  array_add dt_atmos v$dt days v$days seconds v$secs
  # Set horizontal coordinates
  ntrunc=${reso%l*}
  ntrunc=${ntrunc#t}
  case $ntrunc in
    42)  nlat=64  ;;
    63)  nlat=96  ;;
    85)  nlat=128 ;;
    95)  nlat=144 ;; # for 36-core Cheyenne nodes
    106) nlat=160 ;;
    170) nlat=256 ;;
    *) echo "Error: Invalid truncation number \"$ntrunc\"." 1>&2
       exit 1 ;;
  esac
  nsphere=$(($ntrunc + 1)) # forget what difference between num fourier and num spherical means
  nlon=$(($nlat * 2)) # always twice the res
  array_add num_fourier v$ntrunc num_spherical v$nsphere lat_max v$nlat lon_max v$nlon
  # Now vertical resolution options
  # Will raise error if string-specifier is unknown
  vert=${reso#*l}
  case $vert in
    *e) coord=input;      nlev=60;        levels=$f90dir/levels_era.nml ;; # ERA-Interim coordinates
    *p) coord=pk_sigma;   nlev=${vert%p}; levels= ;;
    *s) coord=even_sigma; nlev=${vert%s}; levels= ;;
    *) echo "Error: Unknown vertical coordinate identifier \"${vert}\"." 1>&2
       exit 1 ;;
  esac
  array_add num_levels v$nlev vert_coord_option v\'$coord\'

  #----------------------------------------------------------------------------#
  # Add arrays to namelist
  #----------------------------------------------------------------------------#
  # Copy over the default namelist
  nml=$exp_dir/input.nml
  nml_default=$f90dir/general_default.nml
  cp $nml_default $nml # move over defaut
  echo "Copied $nml_default to $nml"
  # Message
  index=0; width=6; while [ $index -le ${#nml_params[@]} ]; do
    message+="${nml_params[@]:$index:$width}\n${nml_values[@]:$index:$width}\n\n"
    let index+=$width
  done
  printf "Updated namelist with:\n$message" | column -t
  # Also print CFL number
  # 100m/s is around 200mph, which is feasible in jet stream
  echo "CFL num for 100m/s wind: $(echo "scale=3; 100 / ((3.14 * 6371000.0 / $nlat ) / $dt)" | bc | awk '{printf "%f", $0}')."
  # Add forcing namelist
  nml_forcing=$f90dir/forcing_default.nml
  if [ ! -r "$nml_forcing" ]; then
    echo "Error: File \"$nml_forcing\" not found." 2>&1
    exit 1
  fi
  cat $nml_forcing >>$nml # append that shit
  # Add coordinate namelist, potentially
  if [ -n "$levels" ]; then
    if ! [ -r "$levels" ]; then 
      echo "Error: File \"$levels\" not found." 2>&1
      exit 1
    fi
    cat $levels >>$nml
  fi
  # Now loop through variables and assign them
  # Only modify the parameter sweep variables, resolution variables, and
  # timing variables. For others, just change in the namelist file directly.
  [ ${#nml_params[@]} -ne ${#nml_values[@]} ] && echo "Error: One of the batch script namelist params is unset." && exit 1
  for i in $(seq 0 $((${#nml_params[@]}-1))); do
    key=${nml_params[$i]}
    val=${nml_values[$i]}
    [ -z "$key" ] && continue # e.g. stratosphere timescale should be empty
    if ! grep '^[ \t]*\b'${key}'\b' $nml &>/dev/null; then
      echo "Error: Param \"${key}\" not found in namelist." 2>&1
      exit 1
    fi
    space='\([ \t]*\)' # space atom; more readable to set it as a variable
    sed -i 's/^'"${space}${key}${space}"'='"${space}"'.*$/\1'${key}'\2=\3'${val}',/g' $nml
    sed -i 's/^'"${space}${key}${space}"'='"${space}"'.*$/\1'${key}'\2=\3'${val}',/g' $nml
  done
  # Remove comments to be safe
  sed -i 's/!.*$//g;/^[ \t]*$/d' $nml # remove comments

  #------------------------------------------------------------------------#
  # Set up diag table; so far this is kept very simple
  #------------------------------------------------------------------------#
  diag="$exp_dir/diag_table"
  [ $testmode -eq 2 ] && diag_default=$f90dir/diag_table_init || diag_default=$f90dir/$diag_table
  cp $diag_default $diag
  sed -i 's/filename/"'$filename'"/g;s/outfreq/'$outfreq'/g;s/frequnits/"'$frequnits'"/g' $diag
  sed -i 's/#.*$//g;/^[ \t]*$/d' $diag # remove comments, empty lines, for clarity
}

#------------------------------------------------------------------------------#
# Loop through different parameters
# Settings to run entire loop as concurrent qsub processes, or run
# serially on a normal server
#------------------------------------------------------------------------------#
# First set looping params
echo
echo "Forcing: $force, Sweep: $sweep, Resolution: $reso"
exp_names=() # record completed experiments
cwd=$(pwd)
if [[ $sweep =~ base ]]; then
  params1=(na)
  params2=(na)
elif [ -z "$params1" ]; then
  echo "Error: You must define an array of parameters with e.g. --1=10,20,30" && exit 1
elif [ -z "$params2" ]; then
  case $sweep in
    katmos[123]-kfric|katmos[123]-tgrad|katmos[123]-tshift|kstrat[01])
      echo "Error: You must define a second array of parameters with e.g. --2=10,20,30"
      exit 1
      ;;
    *) params2=(na)
      ;;
  esac
fi
# Parameter sweeps
counter=0
# echo ${params1[@]}
# echo ${params2[@]}
for param2 in ${params2[@]}; do
  for param1 in ${params1[@]}; do
    # Get experiment name and directory
    # Prevent repeating experiments during diagonal param sweeps
    exp_name=$(exp_name $sweep $param1 $param2)
    ! [ -d logs ] && mkdir logs
    if array_in $exp_name ${exp_names[@]}; then
      echo "Already processed ${exp_name} in this loop."
      continue
    fi
    exp_names+=($exp_name) # record in list
    case $testmode in
      0) exp_dir="$scratch/$exp_name" ;; # running model
      1) exp_dir="$scratch/$testname" ;;
      2) exp_dir="$scratch/$initname" ;;
    esac
    [ ! -d "$exp_dir" ] && mkdir "$exp_dir"
    log=logs/${exp_dir##*/}.log # e.g use the testing name
    echo "Experiment name: ${exp_name}." | tee $log
    echo "Log file: log $log" # so can copy paste this
    echo "Run flags: $flags_global"

    # Prepare namelist, diag table, and flags for experiment
    # NOTE: This sets global variables 'exp_name' and 'exp_dir'
    unset flags
    exp_setup $exp_name 1>>$log
    [ $counter -ge 1 ] && unset rdir # allow override for first experiment
    if ! [ -z "$rdir" ] && [ $runmode -eq 0 ]; then
      echo "Warning: Using \"${rdir}\" for restart files." | tee $log
      flags+="-rd=$scratch/$rdir/$rdays " # override with this restart directory
    fi
    ! [ -z "$txyzdata" ]  && flags+="-dxyz=$txyzdata " # keep XYZ data
    ! [ -z "$tnodata" ]   && flags+="-dn=$tnodata " # record zero data
    ! [ -z "$tspindown" ] && flags+="-ds=$tspindown " # record zero data

    # Run experiment (or just echo command for dryrun)
    np=$((cores * nodes))
    exp_run="./drycore_run $exp_dir $flags_global $flags -m=$runmode -ts=$tstart -te=$tend -c=$np -p='$pflags'"
    $dryrun && echo $exp_run && continue
    # On server
    # NOTE: Need the eval so the quotes in the -p argument are evaluated
    if ! $super; then
      eval "$exp_run &>>$log"
      if [ $? -ne 0 ]; then
        printf "Warning: $exp_name integration failed.\n\n\n\n"
        continue # keyboard interruption does not trigger this
      fi
    # On supercomputer, submit via qsub
    # NOTE: See Readme and subfolders in 'logs' folder to see rationale
    # for core selection; found that *mpiprocs/openmp flags made no change*,
    # while got better performance using 40 cores instead of 40 cpus.
    # NOTE: Use economy queue because I work at weird times, have never
    # really noticed big slowdowns or wait times
    else
      ! [ -d jobs ] && mkdir jobs
      qsub <<EOF
#!/usr/bin/env bash
# Job name, account, email
#PBS -N $exp_name
#PBS -A UCSU0071
#PBS -M lukelbd@gmail.com
#PBS -m ae
#PBS -q $queue
# Job specs (max possible walltime is 12 hours)
#PBS -l walltime=$walltime:00
#PBS -l select=$nodes:ncpus=$cores:mpiprocs=$cores
# Output
#PBS -j oe
#PBS -k o
# Command
$exp_run &>>$log
EOF
    fi
    # Wrap up
    ! [ -d $HOME/data ] && mkdir $HOME/data
    ! [ -d $HOME/data/forcing ] && mkdir $HOME/data/forcing
    unset flags
    let counter+=1
    cd $cwd # ensure are still in same directory
    echo
  done
done
# echo # space
