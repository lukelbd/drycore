#!/usr/bin/env bash
################################################################################
# NOTE: Previously sweeped parameter space with ugly hodgpodge of exact doubling;
# dividing into 1, 2.5, 5; and diving into 1, 2, 4; now, we always use the 1, 2, 4
# to logarithmically sweep space. Existing directories have been moved to their
# closest values in this new spacing. White lie, but probably insignificant differences.
################################################################################
usage='drycore_series [OPTION...] "FORCING_SWEEP_RESOLUTION" --1=[prev:]value[,...] [--2=[prev:]value[,...]] '
doc="This script runs a parameter sweep for the given input series and
list(s) of parameters, using the 'run' script. It generates standardized
folder names and can modify the namelist and diag_table for the parameters
being changed.

Usage

  $usage

Valid forcing specs

  The number indicates the boundary layer damping approach: 1 is constant
  everywhere, 2 employs faster damping, and 'L' stands for 'locked'. Note that
  this script trims the suffix, and the model actually expects just those strings.

  hs[12][LC]     Held and Suarez, 1994
  pk[12][LC]     Polvani and Kushner, 2004
  pkmod[12][LC]  Polvani and Kushner with modified coords

Valid sweep specs

  In most cases, the number indicates the boundary layer option.

  base            Just run forcing scheme with default settings, once
  tdamp           Change tropospheric damping.
  tdampmean       Change mean component of tropospheric damping.
  tgrad           Change equator-pole teq difference.
  tmean           Change global mean surface teq.
  tshift          Shift teq meridional gradient poleward or equatorward
  fdamp           Change friction.
  tdamp-tgrad     Change both tropospheric damping and equator-pole eqtemp difference
  tdamp-tshift    Change both tropospheric damping and temp gradient shift
  tdamp-fdamp     Change both friction and tropospheric damping.
  tdampstrat      Change stratospheric damping; number is
                  troposphere-stratosphere damping transition option.

Valid resolution specs

  A string with the format 't[XX]l[YY][spe]'

  * XX is truncation number.
  * YY is vertical level count.
  * Suffix is one character controlling level spacing type:
    * evenly-spaced [s]igma levels
    * unevenly-spaced [p]olvani and kushner sigma levels
    * [e]ra-interim hybrid levels, specified by namelist named
      levels_ecwmf_{YY}.nml in source directory

Valid parameter specs

  Passed with the flags --1=[prev:]value[,...] [--2=[prev:]value[,...]]

  * --1 is the first parameter for the sweep spec, and --2 is the optional
    second parameter, if this is a diagonal sweep.
  * To run from the end of a *previous* run in the same experiment series,
    use --1=prev:value, e.g. --1=20,40,40:100,100:200.
  * The experiment directory names will be 'force_sweep_resolution_p[XXX][p[YYY]]'
    for parameter 1 XXX and parameter 2 YYY Directories are renamed if
    specified parameters correspond to the 'base' HS94 values.

Optional arguments

  -h|--help             Print this message.
  -t|--test             Run quick test, just a few days, maybe 3 restarts.
  -i|--init             Just run model to get a forcing.nc file.
  -s|--save             Save thermal damping tendency tdt for every run?
  [-c|--cores]=*        Number of cores.
  [-n|--nodes]=*        Number of nodes, if this is a supercomputer.
  [-d|--days]=*         Number of days.
  [-dt|--timestep]=*    Number of timesteps.
  [-td|--testdays]=*    Number of days in each test run block.
  [-tb|--testblocks]=*  Number of blocks for test run.
  [-ts|--tstart]=*      Initial day.
  [-te|--tend]=*        Final day.
  [-kts|--ktstart]=*    Initial day where we start keeping full-res data.
  [-kte|--ktend]=*      Final day that we keep full-res data.
  -*                    Unknown flags passed to run script.
"
# Notes
# * Really can't push CFL number! Shoot for around 0.5. Got almost instant
#   model blow up at 1200s with T106, since upper-level winds probably get to
#   around 100m/s (about 200mph)
# * Working times so far 20 days, 40 days: 600s, even 800s too fast;
#   100 days: 800s.
rundir=$HOME/gfdl-fms/exp # model folder for namelists and stuff
source $rundir/header.sh
cwd=${0%/*}
cd $cwd
[ $? -ne 0 ] && echo "Error: Header file not found." && exit 1
module load impi &>/dev/null
module load nco &>/dev/null
# module load ncl &>/dev/null # use conda versions instead, already on path
# module load cdo/1.9.4 &>/dev/null

# Default settings
rdays=50
nodes=1
cores=8
mail=false
dryrun=false
locked=false # locked heating run
savetdt=false
dt=600 # for T106, gives 100m/s CFL number of 0.5
tstart=0
tend=5500
walltime=12:00
queue=economy
outfreq=12      # every 6
frequnits=hours # hours
filename=2xdaily_inst # name for output files
ktstart=1 # first day we keep XYZ data (can't keep all, too much data)
ktend=0 # last day we keep XYZ data
testmode=false
testdays=5
testblocks=5 # number of blocks of testdays

# For supercomputer, idea will be to submit all jobs for the series
# simultaneously, by auto-generating a PBS script
super=false
[[ $HOSTNAME =~ cheyenne* ]] && super=true

# Parse input
gflags="-p=$cwd/process_inline -pi=$cwd/process_init "
while [ $# -gt 0 ]; do # echo "Flag: $1"
  case "$1" in
    -h|--help) echo "$doc" && exit 0 ;;
    -t|--test) testmode=true ;;
    -d|--dryrun) dryrun=true ;;
    -s|--save) savetdt=true ;;
    -1=|--1=*) params1=($(echo ${1#*=} | tr ',' ' ')) ;;
    -2=|--2=*) params2=($(echo ${1#*=} | tr ',' ' ')) ;;
    -c=*|--cores=*) cores=${1#*=} ;;
    -n=*|--nodes=*) nodes=${1#*=} ;;
    -d=*|--days=*) rdays=${1#*=} ;;
    -dt=*|--timestep=*) dt=${1#*=} ;;
    -ts=*|--tstart=*) tstart=${1#*=} ;;
    -te=*|--tend=*) tend=${1#*=} ;;
    -kts=*|--ktstart=*) ktstart=${1#*=} ;;
    -kte=*|--ktend=*) ktend=${1#*=} ;;
    -td=*|--testdays=*) testdays=${1#*=} ;;
    -tb=*|--testblocks=*) testblocks=${1#*=} ;;
    -*) gflags+="$1 " ;;
    *) [ -n "$series" ] && raise "More than one experiment series specified."
       series="$1" ;;
  esac
  shift
done

# Default experiment series
if [ -z "$series" ]; then
  echo "Warning: No experiment name specified. Running default experiment hs1_base_t42l20s."
  series='hs1_base_t42l20s'
fi

# Parse experiment series name
# Also echo the critical parallelization info
echo "Nodes: $nodes, Cores: $cores"
force="${series%%_*}"
sweep="${series#*_}"
sweep="${sweep%%_*}"
reso="${series#*_}"
reso="${reso#*_}"
reso="${reso%%_*}"

# Forcing options, not part of the parameter sweep but representing
# qualitative variations of the model forcing scheme
locked=false
[[ "$force" =~ L$ ]] && force="${force%L}" lock=L cold=false
[[ "$force" =~ C$ ]] && force="${force%C}" lock=C cold=true
[[ "$force" =~ [0-9]$ ]] || raise "Forcing spec must end with a number, indicating the boundary layer damping option."
[ -n "$lock" ] && locked=true savetdt=false
forceopt=${force##*[a-z]} # get number
force=${force%[0-9]}

# Run really fast test run
if $testmode; then
  # exprestart="${force}_base2_t95l60e" # override previous directory
  gflags+=' -d'
  outfreq=12
  frequnits=hours
  filename=test
  rdays=$testdays
  tstart=0
  tend=$((testdays * testblocks))
  ktstart=$tstart
  ktend=$tend
  walltime=01:00 # real quick test
  queue=regular
fi

#------------------------------------------------------------------------------#
# Storage and model path
#------------------------------------------------------------------------------#
storage=$HOME
scratch=$HOME # on Euclid, home is unmounted/not backed up; so disk I/O is quick
case ${HOSTNAME%%.*} in
  euclid)
    storage=/birner-home/ldavis # this directory is backed up; synced with GAUSS home folder
  ;; monde)
    case $reso in
      # t42l20s) scratch=/mdata2/ldavis ;;
      t42l20?) scratch=/mdata1/ldavis ;;
      t95l60?) scratch=/mdata1/ldavis ;;
      *) raise "Unknown scratch destination for experiment with resolution ${reso}." ;;
    esac
  ;; cheyenne*)
    storage=/glade/u/home/davislu
    scratch=/glade/scratch/davislu # https://www2.cisl.ucar.edu/resources/storage-and-file-systems/glade-file-spaces
  ;; *) raise "Unknown host, must edit batch script before continuing." ;;
esac
[ -d "$storage/data" ] || { mkdir "$storage/data"; echo "Created storage directory."; }

#------------------------------------------------------------------------------#
# Helper functions
#------------------------------------------------------------------------------#
# Determine model run name, accounting for "intersection" of experiment series
# and specifying named parameter values for forcing experiments
# Sets global model run variables 'exprestart' and 'expname'
exp_name() {
  # Get params for this experiment and the "continuation" experiment, e.g.
  # --1=40:100 means run this experiment with parmeter 100, from experiment
  # with parameter 40.
  # NOTE: Cannot have "diagonal" continuation experiments, they should always
  # be from an adjacent run in a linear the experiment series.
  local p1 p2 p1f p2f param1 param2 rparam1 rparam2 contin
  local isweep fsweep prefix suffix
  param1=$2
  param2=$3
  isweep=${1#*_}
  isweep=${isweep%%_*} # e.g. tdamp, tgrad
  [[ $param1 =~ : ]] && rparam1=${param1%:*} param1=${param1#*:}
  [[ $param2 =~ : ]] && rparam2=${param2%:*} param2=${param2#*:}
  [ -n "$rparam1" ] && [ -n "$rparam2" ] && raise "Cannot do 'diagonal' continuation experiments."

  # Detect whether this is a 'base' experiment. Experiment series can
  # 'intersect' each other, and this ensures we aren't duplicating model runs
  for p1 in $rparam1 $param1; do
    for p2 in $rparam2 $param2; do
      # Continuation experiments get a special suffx
      [ -n "$expname" ] && exprestart="$expname" contin=c
      # Get experiment sweep name, *ensuring that we avoid duplicating runs
      # by deferring to different names when possible*
      # TODO: Add to these.
      prefix=${sweep%-*}
      suffix=${sweep#*-}
      fsweep=$isweep # by default, will be same
      # Params for this experiment name
      # WARNING: Can get issues if e.g. go from tdamp-tmean base state to
      # pure tmean or tdamp experiment. Never overwrite the 'p1' and 'p2' input
      # parameters we are looping through.
      p1f=$p1
      p2f=$p2
      case $isweep in
        # 1D parameter sweeps, pretty simple
        base) p1f= p2f= ;;
        tgrad) [[ $p1 == 60 ]] && fsweep=base p1f= ;; # base is 60K contrast
        tmean) [[ $p1 == 300 ]] && fsweep=base p1f= ;; # base is 300K mean
        fdamp) [[ $p1 == 1 ]] && fsweep=base p1f= ;;
        tshift) [[ $p1 == 0 ]] && fsweep=base p1f= ;; # zero just means no shift
        tdampstrat) [[ $p1 == 40 ]] && fsweep=base p1f= ;; # always use classic Held-Suarez for these, i.e. non-constant boundary layer damping
        tdamp|tdampmean|tdampanom) [[ $p1 == 40 ]] && fsweep=base p1f= ;; # base is 40 day zonal-mean or anomaly damping
        *) [ -z "$p2" ] && raise "Need second param for diagonal experiment."
        # True 'diagonal' experiments
        # WARNING: Order is important here! Have to detect 'base' experiments
        # before the other ones.
        case "$isweep" in # diagaonal experiment
          tdamp-tgrad)
            [[ $p2 == 60 ]] && fsweep=tdamp p2f=
            [[ $p1 == 40 ]] && fsweep=tgrad p1f=$p2 p2f=
            [[ $p1 == 40 && $p2 == 60 ]] && fsweep=base p1f= p2f=
            ;;
          tdamp-tmean)
            [[ $p2 == 300 ]] && fsweep=tdamp p2f=
            [[ $p1 == 40 ]] && fsweep=tmean p1f=$p2 p2f=
            [[ $p1 == 40 && $p2 == 300 ]] && fsweep=base p1f= p2f=
            ;;
          tdamp-tshift)
            [[ $p2 == 0 ]] && fsweep=tdamp p2f=
            [[ $p1 == 40 ]] && fsweep=tshift p1f=$p2 p2f=
            [[ $p1 == 40 && $p2 == 0 ]] && fsweep=base p1f= p2f=
            ;;
          tdamp-fdamp)
            [[ $p2 == 1 ]] && fsweep=tdamp p2f=
            [[ $p1 == 40 ]] && fsweep=fdamp p1f=$p2 p2f=
            [[ $p1 == 40 && $p2 == 1 ]] && fsweep=base p1f= p2f=
            ;;
          tgrad-tshift)
            [[ $p2 == 0 ]] && fsweep=tgrad p2f=
            [[ $p1 == 60 ]] && fsweep=tshift p1f=$p2 p2f=
            [[ $p1 == 60 && $p2 == 0 ]] && fsweep=base p1f= p2f=
            ;;
          # Forcing experiments
          tdamp-arctic|tdamp-tropical|tdamp-vortex|tdamp-global|tdamp-surface)
            [[ $p2 == 0 ]] && fsweep=tdamp p2f=
            [[ $p1 == 40 ]] && fsweep=${isweep#*-} p1f=$p2 p2f=
            [[ $p1 == 40 && $p2 == 0 ]] && fsweep=base p1f= p2f=
            ;;
          *) raise "Unknown sweep \"${isweep}\"." ;;
        esac
        ;;
      esac
      [ "$p1f" == 'na' ] && unset -v p1f
      [ "$p2f" == 'na' ] && unset -v p2f
      [ -n "$p1f" ] && p1f="_p$(printf "%08.3f" $p1f)"
      [ -n "$p2f" ] && p2f="p$(printf "%08.3f" $p2f)"
      expname=${force}${forceopt}${lock}_${fsweep}_${reso}${p1f}${p2f}${contin}
    done
  done

  # Override
  if $locked; then
    expname=${expname%c} # ignore trailing c
    expheating=${expname/[LC]/}
    [ -d $scratch/$expheating ] || expheating=${expheating}c
    [ -d $scratch/$expheating ] || raise "Heating directory \"$scratch/${expheating}c\" or \"$scratch/$expheating\" not found."
    if $cold; then
      unset exprestart
    else
      exprestart=$expheating
    fi
  fi
}

# Determine namelist changes and diag table changes
# WARNING TODO: Currently don't explicitly declare all param variables; they
# are global values, and if not reset on every iteration of diagonal experiment,
# could get unexpected namelist values! Make sure to unset variables that are
# changed in a param sweep.
exp_setup() {
  # Parse the experiment name, figure out what needs to be written
  # The 'p values' are values specified in experiment name as pXXXpYYYpZZZ
  local kbl ktrop kstrat kmeso kdepth kfric levels damp delh exph tmean params sweep message
  local q0_arctic q0_tropical q0_vortex q0_global q0_surface
  unset nml_params nml_values
  sweep=${1#*_}
  sweep=${sweep%%_*}
  if [[ "$1" =~ _p[0-1] ]]; then # i.e. has param values on end
    params=${1##*_}
    params=${params%c}
    params=($(echo $params | tr -t 'p' ' ' | xargs printf "%.3f "))
  fi
  # First the boundary layer options
  prefix=${sweep%-*}
  suffix=${sweep#*-}
  [[ $forceopt -lt 1 || $forceopt -gt 3 ]] && raise "Invalid forcing scheme option ${forceopt}."
  [ $forceopt -eq 2 ] && kbl=-40 # simple default

  # Experiments
  case $sweep in
    # Simple experiments
    base) ;;
    tshift) exph=${params[0]} ;; # shift meridional temp gradient
    tmean) tmean=${params[0]} ;; # change mean surface temp
    fdamp) kfric=-${params[0]} ;; # change friction damping

    # Tgrad, and related diagonal experiments
    tgrad|tgrad-*)
      delh=${params[0]}
      if [ $sweep != $suffix ]; then # i.e. experiment had a 'dash' in it
        [ -z "${params[1]}" ] && raise "Need second param for diagonal experiment."
        case $suffix in
          tshift) exph=${params[1]} ;;
          *) raise "Unknown sweep ${sweep}." ;;
        esac
      fi
      ;;

    # Damp full atmosphere, and related diagonal experiments
    tdamp|tdampmean|tdampanom|tdamp-*|tdampmean-*|tdampanom-*)
      ktrop=-${params[0]}
      # Mean and anomaly components
      case $sweep in
        tdampmean) ktrop=-40,$ktrop ;;
        tdampanom) ktrop=$ktrop,-40 ;;
      esac
      # Diagonal experiments
      if [ $sweep != $suffix ]; then # i.e. experiment had a 'dash' in it
        [ -z "${params[1]}" ] && raise "Need second param for diagonal experiment."
        case $suffix in # diagaonal experiment
          fdamp) kfric=-${params[1]} ;;
          tgrad) delh=${params[1]} ;;
          tmean) tmean=${params[1]} ;;
          tshift) exph=${params[1]} ;;
          global) q0_global=${params[1]} ;;
          surface) q0_surface=${params[1]} ;;
          arctic) q0_arctic=${params[1]} ;;
          vortex) q0_vortex=${params[1]} ;;
          tropical) q0_tropical=${params[1]} ;;
          *) raise "Unknown sweep ${sweep}." ;;
        esac
      fi
      # Scale boundary layer damping rates
      # TODO: Delete option 3 cuz it was dumb.
      unset kbl
      for itrop in ${ktrop/,/ }; do
        case $forceopt in
          1) ibl=-$(bc -l <<< "scale=3; ${itrop#-}/10") ;; # hold ratio constant
          2) ibl=$itrop ;; # keep surface boundary layer equal to value in rest of atmosphere
          *) raise "Unknown forcing option ${forceopt}." ;;
          # 3) ibl=-$(bc -l <<< "scale=3; (4^-1 + (${itrop#-}^-1 - 40^-1))^-1") ;; # preserve 'boundary layer' component
        esac
        kbl=$kbl,$ibl
      done
      kbl=${kbl#,} # trim leading comma
      # Match strat and meso forcing, no matter whether this is hs or pk
      kstrat=$ktrop
      kmeso=$ktrop
      ;;

    # Damp stratosphere
    tdampstrat|tdampmeanstrat|tdampanomstrat) # stratosphere damping
      # Get two parameters
      [ -z "${params[1]}" ] && raise "Need to specify transition depth as second parameter."
      kstrat=-${params[0]}
      kdepth=${params[1]} # param 2 is depth of transition region
      # Mean and anomaly components
      case "$name" in
        tdampanomstrat) kstrat=-40,$kstrat ;;
        tdampmeanstrat) kstrat=$kstrat,-40 ;;
      esac
      # Whether to damp mesosphere more stronly
      # TODO: Add this as forcing scheme prefix? For now just fix to constant.
      damp=constant
      ;;

    *) raise "Unknown experiment series \"$sweep\"." ;;
  esac

  # Apply namelist changes
  nml=$expdir/input.nml
  nml_default=$rundir/input.nml
  cp $nml_default $nml # move over defaut

  # Forcing settings
  nml_replace $nml \
    teq_mode "'$force'" damp_mode "'$force'" strat_damp "'$damp'"
  nml_replace $nml \
    delh "$delh" t_mean "$tmean" exp_h "$exph" # equilibrium temp stuff
  nml_replace $nml \
    ktrop "$ktrop" kfric "$kfric" kbl "$kbl" kstrat "$kstrat" kmeso "$kmeso" z_kdepth "$kdepth" # damping stuff
  nml_replace $nml \
    q0_arctic "$q0_arctic" q0_tropical "$q0_tropical" q0_vortex "$q0_vortex" q0_global "$q0_global" q0_surface "$q0_surface" # global constant forcing

  # Timing variables, not experiment dependent so far
  nml_replace $nml \
    dt_atmos "$dt" days "$rdays"

  # Horizontal coordinates
  ntrunc=${reso%l*}
  ntrunc=${ntrunc#t}
  case $ntrunc in
    42) nlat=64 ;;
    63) nlat=96 ;;
    85) nlat=128 ;;
    95) nlat=144 ;; # for 36-core Cheyenne nodes
    106) nlat=160 ;;
    170) nlat=256 ;;
    *) raise "Invalid truncation number \"$ntrunc\"." ;;
  esac
  nsphere=$(($ntrunc + 1)) # forget what difference between num fourier and num spherical means
  nlon=$(($nlat * 2)) # always twice the res
  nml_replace $nml num_fourier "$ntrunc" num_spherical "$nsphere" lat_max "$nlat" lon_max "$nlon"

  # Now vertical resolution options
  # Will raise error if string-specifier is unknown
  vert=${reso#*l}
  case $vert in
    *e) coord=input levels=$rundir/levels_ecmwf_${nlev}.nml ;; # ERA-Interim coordinates
    *p) coord=pk_sigma nlev=${vert%p} ;;
    *s) coord=even_sigma nlev=${vert%s} ;;
    *) raise "Unknown vertical coordinate identifier \"${vert}\"." ;;
  esac
  nml_replace $nml num_levels "$nlev" vert_coord_option "'$coord'"
  if [ -n "$levels" ]; then # add vert coord namelist
    [ -r "$levels" ] || raise "File \"$levels\" not found."
    cat $levels >>$nml
  fi

  # Print nicely formatted message showing the things we changed
  nml_clean $nml
  nml_print

  # Copy diag table and apply settings
  diag=$expdir/diag_table
  cp $rundir/diag_table $diag
  diag_replace $diag $filename $outfreq $frequnits
  diag_clean $diag

  # Copy field table
  field=$expdir/field_table
  cp $rundir/field_table $field

  # Add tdt line for some experiments
  # if false; then
  if $savetdt; then
    diag_add $diag \
      '"mean_tdt", -1, "hours", 1, "days", "time",' \
      '"forcing", "tdt", "tdt", "mean_tdt", "all", .true., "none", 2,'
  fi

  # Copy input topography and heating
  if $locked; then
    nml_replace $nml locked_heating '.true.'
    unset tdtfiles
    for tdtfile in $scratch/$expheating/netcdf/mean_tdt.*.nc; do
      days=${tdtfile%.nc}
      days=${days##*.}
      day1=${days%-*}
      day2=${days#*-}
      [ ${day1#d} -ge $ktstart ] && [ ${day2#d} -le $ktend ] && tdtfiles+=($tdtfile)
    done
    [ ${#tdtfiles[@]} -eq 0 ] && raise "No tdt files found in $scratch/$expheating/netcdf directory."
    tdtfile=${expdir}/heating.data.nc
    echo "Locked heating data: ${tdtfiles[@]##*/}"
    ncra -h -O ${tdtfiles[@]} $tdtfile || raise "Average of $scratch/$expheating/netcdf/mean_tdt.*.nc files failed."
    ncks -h --no-abc -O -v tdt $tdtfile $tdtfile || raise "Cutting $tdtfile variables failed."
  fi
}

#------------------------------------------------------------------------------#
# Run model, looping through different parameters. We can run entire loop as
# concurrent qsub processes, or run serially on a normal server.
#------------------------------------------------------------------------------#
# First set looping params
echo "Forcing: $force, Sweep: $sweep, Resolution: $reso"
if [[ $sweep =~ base ]]; then
  params1=(na)
  params2=(na)
elif [ -z "$params1" ]; then
  raise "You must define an array of parameters with e.g. --1=10,20,30"
elif [ -z "$params2" ]; then
  params2=(na)
fi
# Parameter sweeps
let np=cores*nodes
gflags+="-c=$np -ts=$tstart -te=$tend "
for param2 in ${params2[@]}; do
  for param1 in ${params1[@]}; do
    # Set the expname and exprestart variables
    # Prevent repeating experiments during diagonal param sweeps
    echo
    unset -v expflags expname exprestart # restart, then exp_name may set it again
    exp_name $sweep $param1 $param2
    if [[ " ${expnames[@]} " =~ " ${expname} " ]]; then
      echo "Already ran ${expname} in this loop."
      continue
    fi
    expnames+=($expname) # record in list
    if $testmode; then
      expdir="$scratch/test"
    else
      expdir="$scratch/$expname"
    fi
    [ -d "$expdir" ] || mkdir "$expdir"
    log="$expdir/run.log" # e.g use the testing name
    echo "Experiment name: ${expname}." | tee $log
    if [ -n "$exprestart" ]; then
      [ -d $scratch/$exprestart ] || exprestart="${exprestart}c"
      [ -d $scratch/$exprestart ] || { echo "Warning: Restart directory $exprestart not found."; continue; }
      echo "Restart from: ${exprestart}" | tee $log
      expflags+="-rd=$scratch/$exprestart " # override with this restart directory
    fi

    # Prepare namelist, diag table, and flags for experiment
    # NOTE: This sets global variables expname, nml, diag, and tdtfile
    # WARNING: Cannot pipe output, because that means function before the pipe
    # is a subprocess with its own varaibles, and global variables are deleted!
    exp_setup $expname >>$log
    expflags+="-nml=$nml -diag=$diag "
    $locked && expflags+="-tdt=$tdtfile "

    # Run experiment (or just echo command for dryrun)
    exp_run="$rundir/run spectral $expdir $gflags $expflags"
    $dryrun && cat $log && echo $exp_run && echo && continue
    # Logs
    echo "Log file: $log" # so can copy paste this
    echo "Run flags: $gflags $expflags"
    # On server
    # NOTE: Need the eval so the quotes in the -p argument are evaluated
    if ! $super; then
      eval "$exp_run &>>$log"
      stat=$?
      if ! $testmode; then
        echo "Exit status: ${stat}"
        if $mail; then
          printf "Experiment ${expname} finished with exit status ${stat}. The call signature was '${exp_run}'.\n\nThe logfile is pasted below.\n\n$(cat $log)\n\nThe namelist is pasted below.\n\n$(cat $expdir/input.nml)" \
            | mail -s "${expname} status: ${stat}" lukelbd@gmail.com
        fi
      fi
      if [ $stat -ne 0 ]; then
        echo "Warning: $expname integration failed."
        continue # keyboard interruption does not trigger this
      fi
    # On supercomputer, submit via qsub
    # NOTE: See Readme for core selection rationale
    # NOTE: Use economy queue because I work at weird times, have never
    # really noticed big slowdowns or wait times
    else
      [ -d jobs ] || mkdir jobs
      qsub <<EOF
#!/usr/bin/env bash
# Job name, account, email
#PBS -N $expname
#PBS -A UCSU0071
#PBS -M lukelbd@gmail.com
#PBS -m ae
#PBS -q $queue
# Job specs (max possible walltime is 12 hours)
#PBS -l walltime=$walltime:00
#PBS -l select=$nodes:ncpus=$cores:mpiprocs=$cores
# Output
#PBS -j oe
#PBS -k o
# Command
$exp_run &>>$log
EOF
    fi
    # Wrap up
    [ -d $HOME/data ] || mkdir $HOME/data
    [ -d $HOME/data/forcing ] || mkdir $HOME/data/forcing
    unset flags
    let counter+=1
    cd $cwd # ensure are still in same directory
  done
done
# echo # space
